---
title: "Data Management"
teaching: 0
exercises: 0
questions:
- "Key question (FIXME)"
objectives:
- "How do we manage data?"
keypoints:
- "Long-term archiving, dehydration, workflow presentation (FIXME)"
---

# Now What?
You have determined the relative sentiment of several different
Twitter datasets. You have harvested data from the Twitter
livestream and searched back over the previous six days.

You have gathered timelines on individuals going back years.

## Twitter's TOS and the EU's GDPR
Twitter the corporation allows users to delete (but currently not
edit) their own content. And when the European Union created its
General Data Protection Regulations, it enshrined in las the 'right
to be forgotten.' 

And so, to respect Twitter's Terms of Service as well as what is widely
considered to be a human right, the best practice is to dispose of your
full-data tweets and leave only the tweetID's.

We explored the opposite of this idea earlier in (Ethics
and Twitter)[05-ethics] when we hydrated tweets that had 
been collected after a serous event. We found that many of the 
malicious actors and bots are no longer available in the Twitter
archive. 

However, when we do our research, unless perhaps we are specifically 
looking only at non-person actors or public figures, when our 
research is complete we should always dehydrate our dataset for 
long-term archiving, or before we share data with people outside of 
our immediate research team.

### task: dehydrate something we harvested


## discussion challenge
Was making you log-in to get full-text tax-day tweets a good enough
protection for our taxday dataset?

Which of our datasets would you feel comfortable creating an 
official, UCSB-sponsored archive?
	Bergis Jules' timeline? 
	Library mentions? 
	Library timeline? 
	#FIXME

## DocNow's new tool for consent. 

DocNow released a [new tool](https://www.docnow.io/docnow-app/) that allows for the appraising, collecting, and gathering of consent for social media archives. 
