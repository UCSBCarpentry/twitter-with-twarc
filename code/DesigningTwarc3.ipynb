{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "744056f4-ef73-4c90-a7bc-aef8167fd1cc",
   "metadata": {},
   "source": [
    "# Twitter with twarc\n",
    "A UCSB Carpentry workshop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2b8339f-952b-498f-bc0f-a5eda41a38e0",
   "metadata": {},
   "source": [
    "## Episode 2\n",
    "You should have a taxday.jsonl file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3cbf7282-bf3d-4a51-ad72-008ccaef1a13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usage: twarc2 [OPTIONS] COMMAND [ARGS]...\n",
      "\n",
      "  Collect data from the Twitter V2 API.\n",
      "\n",
      "Options:\n",
      "  --consumer-key TEXT         Twitter app consumer key (aka \"App Key\")\n",
      "  --consumer-secret TEXT      Twitter app consumer secret (aka \"App Secret\")\n",
      "  --access-token TEXT         Twitter app access token for user\n",
      "                              authentication.\n",
      "  --access-token-secret TEXT  Twitter app access token secret for user\n",
      "                              authentication.\n",
      "  --bearer-token TEXT         Twitter app access bearer token.\n",
      "  --app-auth / --user-auth    Use application authentication or user\n",
      "                              authentication. Some rate limits are higher with\n",
      "                              user authentication, but not all endpoints are\n",
      "                              supported.  [default: app-auth]\n",
      "  -l, --log TEXT\n",
      "  --verbose\n",
      "  --metadata / --no-metadata  Include/don't include metadata about when and\n",
      "                              how data was collected.  [default: metadata]\n",
      "  --config FILE               Read configuration from FILE.\n",
      "  --help                      Show this message and exit.\n",
      "\n",
      "Commands:\n",
      "  compliance-job  Create, retrieve and list batch compliance jobs for...\n",
      "  configure       Set up your Twitter app keys.\n",
      "  conversation    Retrieve a conversation thread using the tweet id.\n",
      "  conversations   Fetch the full conversation threads that the input...\n",
      "  counts          Return counts of tweets matching a query.\n",
      "  csv             Convert tweets to CSV.\n",
      "  dehydrate       Extract tweet or user IDs from a dataset.\n",
      "  flatten         \"Flatten\" tweets, or move expansions inline with tweet...\n",
      "  followers       Get the followers for a given user.\n",
      "  following       Get the users that a given user is following.\n",
      "  hydrate         Hydrate tweet ids.\n",
      "  liked-tweets    Get the tweets liked by a specific user_id.\n",
      "  liking-users    Get the users that liked a specific tweet.\n",
      "  lists           Lists API support.\n",
      "  mentions        Retrieve max of 800 of the most recent tweets...\n",
      "  places          Search for places by place name, geo coordinates or ip...\n",
      "  quotes          Get the tweets that quote tweet the given tweet.\n",
      "  retweeted-by    Get the users that retweeted a specific tweet.\n",
      "  sample          Fetch tweets from the sample stream.\n",
      "  search          Search for tweets.\n",
      "  searches        Execute each search in the input file, one at a time.\n",
      "  stream          Fetch tweets from the live stream.\n",
      "  stream-rules    List, add and delete rules for your stream.\n",
      "  timeline        Retrieve recent tweets for the given user.\n",
      "  timelines       Fetch the timelines of every user in an input source of...\n",
      "  tweet           Look up a tweet using its tweet id or URL.\n",
      "  user            Get the profile data for a single user by either...\n",
      "  users           Get data for user ids or usernames.\n",
      "  version         Return the version of twarc that is installed.\n"
     ]
    }
   ],
   "source": [
    "# BASH commands start with a BANG!\n",
    "!twarc2 --help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d2ad701f-463e-40f9-958b-a09721e263d4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "#  what libraries will we need to be loading in our notebook?\n",
    "#  we need to always distinguish between \n",
    "#  running BASH vs. running a line of python.\n",
    "\n",
    "import pandas\n",
    "import twarc_csv\n",
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2082bb24-2751-406c-a918-c8c41d14e7b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jovyan\n"
     ]
    }
   ],
   "source": [
    "# and of course, it's important to know where we are working\n",
    "# I can send a BASH command from my notebook with a !:\n",
    "!pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5913eea7-a65c-4505-b1c5-a846d7a98d23",
   "metadata": {},
   "source": [
    "## Running twarc\n",
    "Let's get the timeline of one of twarc's creators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "222e98bb-b6fa-442e-b1e9-5f5b72e518e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API limit of 3200 reached:  18%|█▉         | 3142/17697 [00:36<02:50, 85.17it/s]\n"
     ]
    }
   ],
   "source": [
    "!twarc2 timeline BergisJules > raw_data/bjules.jsonl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4473db7c-3651-45f7-8c14-0f49b6c5c0f4",
   "metadata": {},
   "source": [
    "### Challenge\n",
    "- Can you find the file called “bjules.jsonl”?\n",
    "- What's the timestamp on the first one. The last one?\n",
    "\n",
    "- How many tweets did you get from Bergis? (we can't tell without flattening)\n",
    "- Download a timeline for a person of your choice. How many tweets did you get? \n",
    "- What’s the oldest one?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbfccda8-2a25-44a3-bb9a-5bdbc2c6d6cb",
   "metadata": {},
   "source": [
    "# Episode 3: examining tweets\n",
    "What comes along with a tweet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "586f4cbf-4741-44e2-a025-9968faf74e77",
   "metadata": {},
   "source": [
    "### Make your jsonl 1 tweet per line\n",
    "This will let you do our most basic unix-y analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7b7bd894-4995-4851-8668-983c3c4c9f35",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     33  849333 9417257 raw_data/bjules.jsonl\n"
     ]
    }
   ],
   "source": [
    "!wc raw_data/bjules.jsonl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bbe2b98-3264-45bc-adc0-f6aa567718cd",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Try again\n",
    "33 lines doesn't mean 33 tweets. I suspected there was more there becauce\n",
    "I got an error message about hitting a limit of 3200. \n",
    "\n",
    "We need to either flatten our tweets, or convert them\n",
    "to a csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b1dc091e-8fb8-49ab-b6d5-58e454d4bc90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████████| Processed 8.98M/8.98M of input file [00:00<00:00, 9.50MB/s]\n"
     ]
    }
   ],
   "source": [
    "# flatten\n",
    "!twarc2 flatten raw_data/bjules.jsonl output_data/bjules_flattened.jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c9015236-250a-4f85-83b0-296431fe65a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████████| Processed 8.98M/8.98M of input file [00:05<00:00, 1.58MB/s]\n",
      "\n",
      "ℹ️\n",
      "Parsed 3166 tweets objects from 33 lines in the input file.\n",
      "Wrote 3166 rows and output 74 columns in the CSV.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# convert\n",
    "!twarc2 csv raw_data/bjules.jsonl output_data/bjules.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "180e3158-2f08-4d08-8e9e-b4ab999e6ef1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    3166  1742043 23565579 output_data/bjules_flattened.jsonl\n",
      "    3167   586043 11658052 output_data/bjules.csv\n"
     ]
    }
   ],
   "source": [
    "# When I did this, I got 3166 tweets (as opposed to the 33 lines that the original file was)\n",
    "! wc output_data/bjules_flattened.jsonl\n",
    "! wc output_data/bjules.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d55e1a66-f173-4adb-898c-572f15c7bbcb",
   "metadata": {},
   "source": [
    "The csv is 1 line longer because it has column headers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab4c78d8-42bd-458c-b618-d1c854fc265f",
   "metadata": {},
   "source": [
    "Can we go back further on his timeline by looking\n",
    "only for Bergis's original content?\n",
    "\n",
    "No--the same limit applies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b29e6727-48e8-4c79-b824-fd109b0e7029",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API limit of 3200 reached:   0%|             | 47/17696 [00:00<03:20, 88.13it/s]\n"
     ]
    }
   ],
   "source": [
    "!twarc2 timeline BergisJules --exclude-retweets --exclude-replies > raw_data/bjules_original"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ec876b9-c5b4-463a-8552-af4c0b97c446",
   "metadata": {},
   "source": [
    "Let's look at out taxday.jsonl file that we prepared for you on April 18."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c876b6-789d-408f-b164-bdd1f6aaddcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "!head -n 1 raw_data/taxday.jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f64d26-ae10-4deb-bf48-47f88b7db62f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d6efcdaf-a547-4a93-95d3-94e4bfcdddff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|████████████████| Processed 111k/111k of input file [00:00<00:00, 25.3MB/s]\n"
     ]
    }
   ],
   "source": [
    "!twarc2 flatten raw_data/bjules_original.jsonl output_data/bjules_original_flat.jsonl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a685310-f080-4ff8-8728-a46ca21f926b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e4a5ce0-373b-4106-8959-31850ae8fb17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A lot comes along! \n",
    "!tail -n 1 taxday.jsonl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e89e3a4e-4955-426a-9081-1ea9739304c9",
   "metadata": {},
   "source": [
    "## Challenge: tax day Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d95d44-829c-431c-bd6c-7ee4b842506a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we harvested 3 hours worth of tweets for you on tax day.\n",
    "# how many tweets?\n",
    "!wc taxday.jsonl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af2f2152-7de1-40d4-9d97-c6aa551ce2fd",
   "metadata": {},
   "source": [
    "## Next harvest\n",
    "Next we'll get just Bergis' original content. \n",
    "In other words, only the tweets that he wrote, not\n",
    "any retweets or replied to other people tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb6ab7f-2bb4-47d0-bfa8-acb7e9ad77ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e67c2f11-27b4-4802-9d94-19589291e94d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3310f048-6ad7-4ee6-bd4e-c727ec8031a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd90d6c-c9b9-41e5-ae9d-6b3c457cbc9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# maybe the last challenge for ep. 3 is examining this shorter file?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29ab11e8-f109-4670-912c-3122ea2b8211",
   "metadata": {},
   "source": [
    "# Episode 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "be3bd639-6118-4983-bb16-1ff7fd3999de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-05-04T23:09:38.000Z - 2022-05-05T00:00:00.000Z: 520\n",
      "2022-05-05T00:00:00.000Z - 2022-05-06T00:00:00.000Z: 14,928\n",
      "2022-05-06T00:00:00.000Z - 2022-05-07T00:00:00.000Z: 14,851\n",
      "2022-05-07T00:00:00.000Z - 2022-05-08T00:00:00.000Z: 13,038\n",
      "2022-05-08T00:00:00.000Z - 2022-05-09T00:00:00.000Z: 14,368\n",
      "2022-05-09T00:00:00.000Z - 2022-05-10T00:00:00.000Z: 13,196\n",
      "2022-05-10T00:00:00.000Z - 2022-05-11T00:00:00.000Z: 14,321\n",
      "2022-05-11T00:00:00.000Z - 2022-05-11T23:09:38.000Z: 17,018\n",
      "\u001b[32m\n",
      "Total Tweets: 102,240\n",
      "\u001b[0m\n",
      "2022-05-04T23:09:39.000Z - 2022-05-05T00:00:00.000Z: 1,864\n",
      "2022-05-05T00:00:00.000Z - 2022-05-06T00:00:00.000Z: 49,995\n",
      "2022-05-06T00:00:00.000Z - 2022-05-07T00:00:00.000Z: 46,706\n",
      "2022-05-07T00:00:00.000Z - 2022-05-08T00:00:00.000Z: 42,001\n",
      "2022-05-08T00:00:00.000Z - 2022-05-09T00:00:00.000Z: 41,864\n",
      "2022-05-09T00:00:00.000Z - 2022-05-10T00:00:00.000Z: 48,382\n",
      "2022-05-10T00:00:00.000Z - 2022-05-11T00:00:00.000Z: 51,410\n",
      "2022-05-11T00:00:00.000Z - 2022-05-11T23:09:39.000Z: 44,767\n",
      "\u001b[32m\n",
      "Total Tweets: 326,989\n",
      "\u001b[0m\n",
      "2022-05-04T23:09:40.000Z - 2022-05-05T00:00:00.000Z: 2,478\n",
      "2022-05-05T00:00:00.000Z - 2022-05-06T00:00:00.000Z: 70,535\n",
      "2022-05-06T00:00:00.000Z - 2022-05-07T00:00:00.000Z: 56,522\n",
      "2022-05-07T00:00:00.000Z - 2022-05-08T00:00:00.000Z: 55,352\n",
      "2022-05-08T00:00:00.000Z - 2022-05-09T00:00:00.000Z: 71,768\n",
      "2022-05-09T00:00:00.000Z - 2022-05-10T00:00:00.000Z: 58,140\n",
      "2022-05-10T00:00:00.000Z - 2022-05-11T00:00:00.000Z: 61,964\n",
      "2022-05-11T00:00:00.000Z - 2022-05-11T23:09:40.000Z: 57,134\n",
      "\u001b[32m\n",
      "Total Tweets: 433,893\n",
      "\u001b[0m\n",
      "2022-05-04T23:09:41.000Z - 2022-05-05T00:00:00.000Z: 4,645\n",
      "2022-05-05T00:00:00.000Z - 2022-05-06T00:00:00.000Z: 98,856\n",
      "2022-05-06T00:00:00.000Z - 2022-05-07T00:00:00.000Z: 117,838\n",
      "2022-05-07T00:00:00.000Z - 2022-05-08T00:00:00.000Z: 120,635\n",
      "2022-05-08T00:00:00.000Z - 2022-05-09T00:00:00.000Z: 90,829\n",
      "2022-05-09T00:00:00.000Z - 2022-05-10T00:00:00.000Z: 85,739\n",
      "2022-05-10T00:00:00.000Z - 2022-05-11T00:00:00.000Z: 94,235\n",
      "2022-05-11T00:00:00.000Z - 2022-05-11T23:09:41.000Z: 112,020\n",
      "\u001b[32m\n",
      "Total Tweets: 724,797\n",
      "\u001b[0m\n",
      "2022-05-04T23:09:42.000Z - 2022-05-05T00:00:00.000Z: 15,536\n",
      "2022-05-05T00:00:00.000Z - 2022-05-06T00:00:00.000Z: 318,531\n",
      "2022-05-06T00:00:00.000Z - 2022-05-07T00:00:00.000Z: 231,626\n",
      "2022-05-07T00:00:00.000Z - 2022-05-08T00:00:00.000Z: 269,840\n",
      "2022-05-08T00:00:00.000Z - 2022-05-09T00:00:00.000Z: 213,476\n",
      "2022-05-09T00:00:00.000Z - 2022-05-10T00:00:00.000Z: 236,725\n",
      "2022-05-10T00:00:00.000Z - 2022-05-11T00:00:00.000Z: 265,722\n",
      "2022-05-11T00:00:00.000Z - 2022-05-11T23:09:42.000Z: 325,467\n",
      "\u001b[32m\n",
      "Total Tweets: 1,876,923\n",
      "\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "## Endpoints: counts\n",
    "!twarc2 counts --text \"(Poker OR poker)\" --granularity \"day\"\n",
    "!twarc2 counts --text \"(Golf OR golf)\" --granularity \"day\"\n",
    "!twarc2 counts --text \"(Basketball OR basketball)\" --granularity \"day\"\n",
    "!twarc2 counts --text \"(Baseball OR baseball)\" --granularity \"day\"\n",
    "!twarc2 counts --text \"(Football OR football)\" --granularity \"day\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc52493-cf69-4298-8617-515a581ead59",
   "metadata": {},
   "outputs": [],
   "source": [
    "## convert to ucsblibrary. Cats will be ep. 6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5af9bd3-debf-4910-a2f1-30a760d599cd",
   "metadata": {},
   "source": [
    "### Converting to csv and dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44e2145d-a912-49ea-8044-544cb11bb38d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!twarc2 csv raw_data/taxday.jsonl output_data/taxday.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23735a74-0dd1-4483-9705-595042b099bc",
   "metadata": {},
   "source": [
    "## final challenge: Cats of Instagram\n",
    "Let’s make a bigger datafile. Harvest 5000 tweets that use the hashtag “catsofinstagram” and put the dataset through the pipeline to answer the following questions:\n",
    "\n",
    "- Did you get exactly 5000?\n",
    "- How far back in time did you get?\n",
    "- What is the most re-tweeted recent tweet on #catsofinstagram?\n",
    "- Which person has the most number of followers in your dataset?\n",
    "- Is it really a person?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a68cc58-0dc5-4255-92f5-0e220b7385ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "!twarc2 search --limit 500 \"#catsofinstagram\" hashtagcats.jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "952eed26-010f-464b-82c9-4699988555b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set --limit of 5000 reached:  41%|▍| Processed 2 days/6 days [00:45<01:04, 5085 \n"
     ]
    }
   ],
   "source": [
    "!twarc2 search --limit 5000 \"#catsofinstagram\" raw_data/hashtagcats.jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c151b25e-f551-445c-93ed-118406e3df40",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(kittens_df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "870d9fb7-03eb-4dcd-9ab8-d4888b008f65",
   "metadata": {},
   "source": [
    "# Episode 5: Ethics & Twitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f046b945-b698-4c9b-b6c4-8047382f16aa",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'columns' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [12]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mcolumns\u001b[49m(kittens_df)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'columns' is not defined"
     ]
    }
   ],
   "source": [
    "columns(kittens_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12ca8fc4-ac95-4535-8146-843e2126e915",
   "metadata": {},
   "source": [
    "# Episode 6: Working with our Tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e70e7058-cdc6-4b96-98ef-03d261c3b051",
   "metadata": {},
   "source": [
    "1. followers\n",
    "1. retweeted-by\n",
    "1. wall\n",
    "1. retweets\n",
    "1. emojis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc855355-2742-47b4-a166-194898ded55b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Episode 6\n",
    "# make the utils folder and get them from the repo\n",
    "# we will make folder for learners:\n",
    "# https://github.com/DocNow/twarc/tree/main/utils\n",
    "\n",
    "!python utils/wall.py raw_data/taxday.jsonl > output_data/taxday_wall.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76d86256-2a22-4031-9a3d-d76b0ba3f3e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# what does this do?\n",
    "# it shows the tweet ID's of the Retweets in your dataset, and how much\n",
    "!python utils/retweets.py raw_data/taxday.jsonl > output_data/taxday_retweets.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceb74589-f708-4ab5-9a2b-00c2478d4020",
   "metadata": {},
   "outputs": [],
   "source": [
    "# how much is that?\n",
    "tax_retweets_df = pandas.read_csv(\"output_data/taxday_retweets.csv\", names=[\"tweetid\", \"retweets\"])\n",
    "tax_retweets_df.head()\n",
    "tax_retweets_df[\"retweets\"].plot(kind = \"hist\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "371d1385-a265-4e0b-a36f-064a9b5ac444",
   "metadata": {},
   "outputs": [],
   "source": [
    "retweet_total = sum(tax_retweets_df[\"retweets\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a974343-f4c3-4e3c-99c7-67d975cea76b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tax_retweets_df[\"retweets\"].plot(kind = \"hist\", loglog=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c5bbf73-444b-41a2-a72c-deb388217096",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TextBlob needs a string, so this won't work.\n",
    "TextBlob(kittens_df).sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d6da4f1-7a9a-47ef-a5ce-d4e5a3920752",
   "metadata": {},
   "source": [
    "# Episode 7: Search and Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afb13818-26a5-4d6a-bcf1-f99b3d7c966c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use Twitter advanced search syntax (everthing in quotes!)\n",
    "# to get tailored results\n",
    "!twarc2 search --limit 800 \"(cute OR fluffy OR haircut) (#catsofinstagram) lang:en\" kittens.jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0ec3cfcd-55cb-4434-b633-b548cb321141",
   "metadata": {},
   "outputs": [],
   "source": [
    "kittens_df = pandas.read_csv(\"output_data/kittens.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c8aa01-430a-4599-a65d-aaac822ff8c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "kittens_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0015b8ec-3e79-46d8-8f76-9aa7c5dc66b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(kittens_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a264ec5-4174-4e62-a3cd-9e16aef94059",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0edf38c5-f6b4-475d-9a2f-ffef08430159",
   "metadata": {},
   "source": [
    "# Episode 8: Analysis Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ccc6de7-126c-4975-8f1e-cacd1140ff34",
   "metadata": {},
   "outputs": [],
   "source": [
    "built-in should come first"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6c3b41d-cfc2-4a41-b710-4145d2fbb0af",
   "metadata": {},
   "source": [
    "### Sentiment Analysis\n",
    "To do this, we need to do a little Python\n",
    "\n",
    "TextBlob is a text processing library that does sentiment analysis. \n",
    "The sentiment property returns a namedtuple of the form Sentiment(polarity, subjectivity). The polarity score is a float within the range [-1.0, 1.0]. The subjectivity is a float within the range [0.0, 1.0] where 0.0 is very objective and 1.0 is very subjective."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd4d69fd-adcc-46a6-9a46-83cb991e52b9",
   "metadata": {},
   "source": [
    "Before we use TextBlob for sentiment analysis, we need to download\n",
    "datasets of words and their associated weights. These are called *corpora*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "423c7d9b-b67d-4b13-8894-75a64654b52d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m textblob.download_corpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6874ca27-b81f-4f4f-911b-68e9fe21384e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentiment(polarity=0.4313034129204853, subjectivity=0.7558201654919634)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# break tweets test column into a list, then .join into one long string \n",
    "kittens_string = ' '.join(kittens_df['text'].tolist())\n",
    "# turn the string into a blob\n",
    "kittens_blob = TextBlob(kittens_string)\n",
    "# get the sentiment\n",
    "kittens_blob.sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "005ba8f5-5054-4fba-8e12-0bade66f4775",
   "metadata": {
    "tags": []
   },
   "source": [
    "The overall sentiment of the language of our kittens tweets is rather positive.\n",
    "And the tweets tend to be subjective."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f7f70c-b9ee-45cf-ad37-7a26cc43d559",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What do you think the sentiment of tax day might be?\n",
    "# get the overall sentiment and see if it matches your prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9856bda0-b290-40a0-ad22-32ece206312b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e03d25-b2af-4102-a418-b6b0532e0aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Episode 9: Data Management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e793dcc-20ec-419e-baab-4b75b308ba0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Episode 10: Don't Map Twitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d4e4d3d-71a6-4fe7-8b30-542ea123b4ad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
