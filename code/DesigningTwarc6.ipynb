{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "744056f4-ef73-4c90-a7bc-aef8167fd1cc",
   "metadata": {},
   "source": [
    "# Twitter with twarc\n",
    "A UCSB Carpentry workshop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1324c4e6-ab87-441e-bd4e-860eec5ccfe8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35e9818e-0cc6-474e-b92b-28467ca18d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# administravia\n",
    "# upon re-start we need to install twarc2 extensions\n",
    "! pip install twarc-csv\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2b8339f-952b-498f-bc0f-a5eda41a38e0",
   "metadata": {},
   "source": [
    "# Episode 2\n",
    "You should have a taxday.jsonl file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cbf7282-bf3d-4a51-ad72-008ccaef1a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BASH commands start with a BANG!\n",
    "!twarc2 --help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "d2ad701f-463e-40f9-958b-a09721e263d4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#  what libraries will we need to be loading in our notebook?\n",
    "#  we need to always distinguish between \n",
    "#  running BASH vs. running a line of python.\n",
    "\n",
    "import pandas\n",
    "import twarc_csv\n",
    "import textblob\n",
    "import nltk\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "2082bb24-2751-406c-a918-c8c41d14e7b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jovyan/twarc_run\n"
     ]
    }
   ],
   "source": [
    "# and of course, it's important to know where we are working\n",
    "# I can send a BASH command from my notebook with a !:\n",
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "8098e978-172e-4949-a531-1a05fa43be25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/jovyan/twarc_run'"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# you can also do this with Python\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc19b894-b858-4966-ae5e-e32bff6bde2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure we are in the twarc_run folder\n",
    "os.chdir(\"twarc_run\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "17a6e89d-7e91-4558-ae3f-aa1026554cef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/jovyan/twarc_run'"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5913eea7-a65c-4505-b1c5-a846d7a98d23",
   "metadata": {},
   "source": [
    "## Running twarc\n",
    "Let's get the timeline of one of twarc's creators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "222e98bb-b6fa-442e-b1e9-5f5b72e518e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!twarc2 timeline BergisJules > raw_data/bjules.jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "eaf04f84-943a-4d7b-a45e-d007e6b5abc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████████| Processed 8.96M/8.96M of input file [00:00<00:00, 10.4MB/s]\n"
     ]
    }
   ],
   "source": [
    "# timeline objects need to be flattened in order to be analyzed as tweets\n",
    "!twarc2 flatten raw_data/bjules.jsonl output_data/bjules_flat.jsonl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4473db7c-3651-45f7-8c14-0f49b6c5c0f4",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Challenge 1\n",
    "- Can you find the file called “bjules_flat.jsonl”?\n",
    "- What's the timestamp on the first one. The last one?\n",
    "\n",
    "- How many tweets did you get from Bergis? (we can't tell without flattening)\n",
    "- Download a timeline for a person of your choice. How many tweets did you get? \n",
    "- What’s the oldest one?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "bab10779-cc96-4ed0-9e47-2e8faac15d93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    473  204742 2872769 output_data/ecodatasci_flat.jsonl\n"
     ]
    }
   ],
   "source": [
    "!twarc2 flatten raw_data/ecodatasci.jsonl > output_data/ecodatasci_flat.jsonl\n",
    "!wc output_data/ecodatasci_flat.jsonl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08892a04-a2be-4353-b64c-43a628e5ae50",
   "metadata": {},
   "source": [
    "## Convert to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "1b29144d-a627-4128-b54f-74439f37a917",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████████| Processed 8.96M/8.96M of input file [00:02<00:00, 3.45MB/s]\n",
      "\n",
      "ℹ️\n",
      "Parsed 3141 tweets objects from 33 lines in the input file.\n",
      "Wrote 3141 rows and output 74 columns in the CSV.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!twarc2 csv raw_data/bjules.jsonl output_data/bjules.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2316f7fe-1614-404c-9516-897fd6415a7b",
   "metadata": {},
   "source": [
    "### Challenge 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "1284486c-4487-401d-b421-20c4597dfedd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# commented line is a solution to challenge 1\n",
    "# !twarc2 timeline ecodatasci > raw_data/ecodatasci.jsonl\n",
    "\n",
    "!twarc2 csv output_data/ecodatasci_flat.jsonl > output_data/ecodatasci.csv \n",
    "ecodatasci_df = pandas.read_csv(\"output_data/ecodatasci.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aecabff-dbda-4c8c-addc-a7132c3df302",
   "metadata": {},
   "outputs": [],
   "source": [
    "!twarc2 flatten raw_data/ecodatasci.jsonl > output_data/ecodatasci_flat.jsonl\n",
    "!twarc2 csv output_data/ecodatasci_flat.jsonl > output_data/ecodatasci.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f31b31-3360-4d6f-84b4-0db227a1a335",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bbfccda8-2a25-44a3-bb9a-5bdbc2c6d6cb",
   "metadata": {},
   "source": [
    "# Episode 3: examining tweets\n",
    "What comes along with a tweet\n",
    "- Look at one_tweet in Jupyter viewer\n",
    "- Look at one_tweet with nano\n",
    "- Look at tweet as csv\n",
    "- Look at all the entities of a tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba9ab04-d27d-42bd-9a60-9f3a7198cff8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbcb8c10-7fe2-4d91-bc0a-7267ec5062cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Let's look at a tweet\n",
    "!twarc2 csv raw_data/one_tweet.jsonl output_data/one_tweet.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99766d53-53ea-4ef2-b201-2e58c89d411d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## To flatten or not flatten"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "586f4cbf-4741-44e2-a025-9968faf74e77",
   "metadata": {},
   "source": [
    "### Make your jsonl 1 tweet per line\n",
    "This will let you do our most basic unix-y analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b7bd894-4995-4851-8668-983c3c4c9f35",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!wc raw_data/taxday.jsonl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bbe2b98-3264-45bc-adc0-f6aa567718cd",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Try again\n",
    "33 lines doesn't mean 33 tweets. I suspected there was more there becauce\n",
    "I got an error message about hitting a limit of 3200. \n",
    "\n",
    "We need to either flatten our tweets, or convert them\n",
    "to a csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1dc091e-8fb8-49ab-b6d5-58e454d4bc90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# flatten\n",
    "!twarc2 flatten raw_data/taxday.jsonl output_data/taxday_flattened.jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd5bd6d9-24f4-4a93-9222-1dad58059328",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wc output_data/taxday_flattened.jsonl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a8c4d85-fa2a-4e7d-9e7c-1fa1207d64fc",
   "metadata": {},
   "source": [
    "## When we look at bjules, we really do need to flatten it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9015236-250a-4f85-83b0-296431fe65a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert\n",
    "!twarc2 csv raw_data/bjules.jsonl output_data/bjules.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "180e3158-2f08-4d08-8e9e-b4ab999e6ef1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# When I did this, I got 3166 tweets (as opposed to the 33 lines that the original file was)\n",
    "! wc output_data/bjules_flattened.jsonl\n",
    "! wc output_data/bjules.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d55e1a66-f173-4adb-898c-572f15c7bbcb",
   "metadata": {},
   "source": [
    "The csv is 1 line longer because it has column headers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab4c78d8-42bd-458c-b618-d1c854fc265f",
   "metadata": {},
   "source": [
    "Can we go back further on his timeline by looking\n",
    "only for Bergis's original content?\n",
    "\n",
    "No--the same limit applies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b29e6727-48e8-4c79-b824-fd109b0e7029",
   "metadata": {},
   "outputs": [],
   "source": [
    "!twarc2 timeline BergisJules --exclude-retweets --exclude-replies > raw_data/bjules_original"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ec876b9-c5b4-463a-8552-af4c0b97c446",
   "metadata": {},
   "source": [
    "Let's look at out taxday.jsonl file that we prepared for you on April 18."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c876b6-789d-408f-b164-bdd1f6aaddcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "!head -n 1 raw_data/taxday.jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f64d26-ae10-4deb-bf48-47f88b7db62f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6efcdaf-a547-4a93-95d3-94e4bfcdddff",
   "metadata": {},
   "outputs": [],
   "source": [
    "!twarc2 flatten raw_data/bjules_original.jsonl output_data/bjules_original_flat.jsonl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a685310-f080-4ff8-8728-a46ca21f926b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e4a5ce0-373b-4106-8959-31850ae8fb17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A lot comes along! \n",
    "!tail -n 1 raw_data/taxday.jsonl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e89e3a4e-4955-426a-9081-1ea9739304c9",
   "metadata": {},
   "source": [
    "## Challenge: tax day Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d95d44-829c-431c-bd6c-7ee4b842506a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we harvested 3 hours worth of tweets for you on tax day.\n",
    "# how many tweets?\n",
    "!wc raw_data/taxday.jsonl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af2f2152-7de1-40d4-9d97-c6aa551ce2fd",
   "metadata": {},
   "source": [
    "## Next harvest\n",
    "Next we'll get just Bergis' original content. \n",
    "In other words, only the tweets that he wrote, not\n",
    "any retweets or replied to other people tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb6ab7f-2bb4-47d0-bfa8-acb7e9ad77ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e67c2f11-27b4-4802-9d94-19589291e94d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3310f048-6ad7-4ee6-bd4e-c727ec8031a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd90d6c-c9b9-41e5-ae9d-6b3c457cbc9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# maybe the last challenge for ep. 3 is examining this shorter file?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29ab11e8-f109-4670-912c-3122ea2b8211",
   "metadata": {},
   "source": [
    "# Episode 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "021f95fb-293d-459c-9afd-59d624efa865",
   "metadata": {},
   "outputs": [],
   "source": [
    "!twarc2 counts --granularity \"day\" --text \"(#UCSBLibrary OR UCSBLibrary OR ucsblibrary OR #ucsblibrary OR davidsonlibrary OR #davidsonlibrary)\"\n",
    "# is it worth doing the OR's? For sure.\n",
    "!twarc2 counts --granularity \"day\" --text \"(#UCSBLibrary OR UCSBLibrary)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be3bd639-6118-4983-bb16-1ff7fd3999de",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Endpoints: counts\n",
    "!twarc2 counts --text \"(Poker OR poker)\" --granularity \"day\"\n",
    "!twarc2 counts --text \"(Golf OR golf)\" --granularity \"day\"\n",
    "!twarc2 counts --text \"(Basketball OR basketball)\" --granularity \"day\"\n",
    "!twarc2 counts --text \"(Baseball OR baseball)\" --granularity \"day\"\n",
    "!twarc2 counts --text \"(Football OR football)\" --granularity \"day\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5443c1c7-0da2-4ad9-82fd-1e9b2b377a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "## What's a lot?\n",
    "!twarc2 counts --text \"dog\" --granularity \"day\"\n",
    "!twarc2 counts --text \"cat\" --granularity \"day\"\n",
    "!twarc2 counts --text \"amazon\" --granularity \"day\"\n",
    "!twarc2 counts --text \"right\" --granularity \"day\"\n",
    "!twarc2 counts --text \"good\" --granularity \"day\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b64d9fa-d4d2-49c3-bf09-1e3a9d0ab35b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "abc52493-cf69-4298-8617-515a581ead59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████████| Processed 5.31M/5.31M of input file [00:00<00:00, 10.7MB/s]\n",
      "100%|██████████████| Processed 12.9M/12.9M of input file [00:02<00:00, 4.79MB/s]\n",
      "\n",
      "ℹ️\n",
      "Parsed 3226 tweets objects from 3226 lines in the input file.\n",
      "Wrote 3226 rows and output 74 columns in the CSV.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## a SFW timeline\n",
    "# !twarc2 timeline ucsblibrary raw_data/library.jsonl\n",
    "!twarc2 flatten raw_data/library.jsonl output_data/library.jsonl\n",
    "!twarc2 csv output_data/library.jsonl output_data/library.csv\n",
    "library_df = pandas.read_csv(\"output_data/library.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc06081-ef7c-4122-b7c0-0901ca4a2dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# confirm the dataframe's existance\n",
    "list(library_df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5af9bd3-debf-4910-a2f1-30a760d599cd",
   "metadata": {},
   "source": [
    "### Converting to csv and dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44e2145d-a912-49ea-8044-544cb11bb38d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!twarc2 csv raw_data/taxday.jsonl output_data/taxday.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb2daed5-e882-4d66-bcdc-f403bb3a6710",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a492aa1b-dd0f-44f0-b0bc-dedec7d38b0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab6d14b4-0c5e-4553-9eb2-7d8d284476af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fishing around for good searches\n",
    "!twarc2 counts --text \"kittens\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee4cc6aa-8a09-4b27-9dab-0b80cf267fcc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "23735a74-0dd1-4483-9705-595042b099bc",
   "metadata": {},
   "source": [
    "## final challenge: Cats of Instagram\n",
    "Let’s make a bigger datafile. Harvest 5000 tweets that use the hashtag “catsofinstagram” and put the dataset through the pipeline to answer the following questions:\n",
    "\n",
    "- Did you get exactly 5000?\n",
    "- How far back in time did you get?\n",
    "- What is the most re-tweeted recent tweet on #catsofinstagram?\n",
    "- Which person has the most number of followers in your dataset?\n",
    "- Is it really a person?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "952eed26-010f-464b-82c9-4699988555b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    5089   901631 17514921 output_data/hashtagcats.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    2022-05-13T17:46:00.000Z\n",
       "1    2022-05-13T17:45:45.000Z\n",
       "2    2022-05-13T17:45:27.000Z\n",
       "3    2022-05-13T17:45:21.000Z\n",
       "4    2022-05-13T17:42:55.000Z\n",
       "Name: created_at, dtype: object"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# !twarc2 search --limit 5000 \"#catsofinstagram\" raw_data/hashtagcats.jsonl\n",
    "!twarc2 csv raw_data/hashtagcats.jsonl > output_data/hashtagcats.csv\n",
    "hashtagcats_df = pandas.read_csv(\"output_data/hashtagcats.csv\")\n",
    "! wc output_data/hashtagcats.csv\n",
    "hashtagcats_df[\"created_at\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "ac420468-385e-4d39-9f8c-d7e5f520c1be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5083    2022-05-11T11:27:29.000Z\n",
       "5084    2022-05-11T11:26:57.000Z\n",
       "5085    2022-05-11T11:26:10.000Z\n",
       "5086    2022-05-11T11:26:05.000Z\n",
       "5087    2022-05-11T11:25:53.000Z\n",
       "Name: created_at, dtype: object"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hashtagcats_df[\"created_at\"].tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f07c72-c097-4db9-8705-32e2b93c6aba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "c151b25e-f551-445c-93ed-118406e3df40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['id',\n",
       " 'conversation_id',\n",
       " 'referenced_tweets.replied_to.id',\n",
       " 'referenced_tweets.retweeted.id',\n",
       " 'referenced_tweets.quoted.id',\n",
       " 'author_id',\n",
       " 'in_reply_to_user_id',\n",
       " 'retweeted_user_id',\n",
       " 'quoted_user_id',\n",
       " 'created_at',\n",
       " 'text',\n",
       " 'lang',\n",
       " 'source',\n",
       " 'public_metrics.like_count',\n",
       " 'public_metrics.quote_count',\n",
       " 'public_metrics.reply_count',\n",
       " 'public_metrics.retweet_count',\n",
       " 'reply_settings',\n",
       " 'possibly_sensitive',\n",
       " 'withheld.scope',\n",
       " 'withheld.copyright',\n",
       " 'withheld.country_codes',\n",
       " 'entities.annotations',\n",
       " 'entities.cashtags',\n",
       " 'entities.hashtags',\n",
       " 'entities.mentions',\n",
       " 'entities.urls',\n",
       " 'context_annotations',\n",
       " 'attachments.media',\n",
       " 'attachments.media_keys',\n",
       " 'attachments.poll.duration_minutes',\n",
       " 'attachments.poll.end_datetime',\n",
       " 'attachments.poll.id',\n",
       " 'attachments.poll.options',\n",
       " 'attachments.poll.voting_status',\n",
       " 'attachments.poll_ids',\n",
       " 'author.id',\n",
       " 'author.created_at',\n",
       " 'author.username',\n",
       " 'author.name',\n",
       " 'author.description',\n",
       " 'author.entities.description.cashtags',\n",
       " 'author.entities.description.hashtags',\n",
       " 'author.entities.description.mentions',\n",
       " 'author.entities.description.urls',\n",
       " 'author.entities.url.urls',\n",
       " 'author.location',\n",
       " 'author.pinned_tweet_id',\n",
       " 'author.profile_image_url',\n",
       " 'author.protected',\n",
       " 'author.public_metrics.followers_count',\n",
       " 'author.public_metrics.following_count',\n",
       " 'author.public_metrics.listed_count',\n",
       " 'author.public_metrics.tweet_count',\n",
       " 'author.url',\n",
       " 'author.verified',\n",
       " 'author.withheld.scope',\n",
       " 'author.withheld.copyright',\n",
       " 'author.withheld.country_codes',\n",
       " 'geo.coordinates.coordinates',\n",
       " 'geo.coordinates.type',\n",
       " 'geo.country',\n",
       " 'geo.country_code',\n",
       " 'geo.full_name',\n",
       " 'geo.geo.bbox',\n",
       " 'geo.geo.type',\n",
       " 'geo.id',\n",
       " 'geo.name',\n",
       " 'geo.place_id',\n",
       " 'geo.place_type',\n",
       " '__twarc.retrieved_at',\n",
       " '__twarc.url',\n",
       " '__twarc.version',\n",
       " 'Unnamed: 73']"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(hashtagcats_df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "870d9fb7-03eb-4dcd-9ab8-d4888b008f65",
   "metadata": {},
   "source": [
    "# Episode 5: Ethics & Twitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "03843c37-975f-44f6-8ab9-459055477e39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jovyan/twarc_run/utils/emojis.py:22: DeprecationWarning: 'emoji.get_emoji_regexp()' is deprecated and will be removed in version 2.0.0. If you want to remove emoji from a string, consider the method emoji.replace_emoji(str, replace='').\n",
      "To hide this warning, pin/downgrade the package to 'emoji~=1.6.3'\n",
      "  EMOJI_RE = emoji.get_emoji_regexp()\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jovyan/twarc_run/utils/emojis.py\", line 29, in <module>\n",
      "    text = tweet[\"text\"]\n",
      "KeyError: 'text'\n"
     ]
    }
   ],
   "source": [
    "# emojis as proxies for text\n",
    "# run the built-in emoji counter/printer\n",
    "! python utils/emojis.py raw_data/hashtagcats.jsonl > output_data/emojis.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f046b945-b698-4c9b-b6c4-8047382f16aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# our first full-text analysis\n",
    "# a list of words with TextBlob\n",
    "\n",
    "# first we need to munge the data. remember from:\n",
    "# list(library_df.columns)\n",
    "# the tweet is library_df['text']\n",
    "\n",
    "# TextBlob has its own data format.\n",
    "\n",
    "# break tweets test column into a list, \n",
    "# then .join into one long string \n",
    "library_string = ' '.join(library_df['text'].tolist())\n",
    "# turn the string into a blob\n",
    "library_blob = TextBlob(library_string)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4522956e-9332-4219-a21b-7e2dfbf3bc02",
   "metadata": {},
   "source": [
    "This produces a mess. we need to filter out the hyperlinks and stop words. And how about a phrase counter?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a5a3b36-fffd-477c-91bb-cdf315dbe285",
   "metadata": {},
   "outputs": [],
   "source": [
    "library_freq = library_blob.word_counts\n",
    "library_sorted_freq = sorted(library_freq.items(), \n",
    "                             key = lambda kv: kv[1], \n",
    "                             reverse = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ebad179-03a4-4f7d-aaf8-7fb366dddd77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# can I just do the first bunch?\n",
    "type(library_sorted_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a69badc7-8fa2-4bd1-b556-ff28318f8642",
   "metadata": {},
   "outputs": [],
   "source": [
    "library_sorted_freq[1:25]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfa676be-7ceb-45e8-82e8-7429b8884d7b",
   "metadata": {},
   "source": [
    "We can at least get the english stopwords out. but this all didn't reall produce anything cleaner:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5cd1c12-d78a-44e5-9376-26b4a0589785",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "sw_nltk = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e878e6b7-2c29-45e8-83cd-fb0eefd3b668",
   "metadata": {},
   "outputs": [],
   "source": [
    "library_str_stopped = [word for word in library_string.split() \n",
    "                       if word.lower() not in sw_nltk]\n",
    "stopped_text = \" \".join(library_str_stopped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e27a5b1-0519-407c-ae52-abd0587857a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "library_blob_stopped = TextBlob(stopped_text)\n",
    "library_blob_stopped_freq = library_blob_stopped.word_counts\n",
    "library_blob_stopped_sorted_freq = sorted(library_blob_stopped_freq.items(), \n",
    "                             key = lambda kv: kv[1], \n",
    "                             reverse = True)\n",
    "library_blob_stopped_sorted_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b658645-2144-45c0-9d76-bac57357e9de",
   "metadata": {},
   "outputs": [],
   "source": [
    "library_stopped_blob = [word for word in library_blob.split()\n",
    "                        if word.lower() not in sw_nltk]\n",
    "new_text = \" \".join(library_stopped_blob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c343fbf8-241c-4ec7-8b6e-da4c3db73717",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(library_stopped_blob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e074d32e-4a94-4add-89b3-cf0863340cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Challenge: for the Python wizzes.\n",
    "# do that in a tidy way?\n",
    "# what do pandas pipes look like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3929ae1c-4a37-4cef-9501-7fc2b540f513",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e99fdaca-edb7-41f1-b35c-a82092579ee0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2bc9aad4-1981-4911-ac2e-18bb3b0e92ae",
   "metadata": {},
   "source": [
    "## Challenge: Insta-rrectionists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe5551d5-4b64-4731-9285-82bfc5fd9a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "!twarc2 hydrate raw_data/dehydratedCapitolRiotTweets.txt output_data/riots.jsonl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76119af0-f58e-4bb4-a296-f0718b28a05b",
   "metadata": {},
   "outputs": [],
   "source": [
    "riots_dehydrated_df = pandas.read_csv(\"raw_data/dehydratedCapitolRiotTweets.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae63a6f5-71af-4a07-a940-d96b45ebd1a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "12ca8fc4-ac95-4535-8146-843e2126e915",
   "metadata": {},
   "source": [
    "# Episode 6: Working with our Tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e70e7058-cdc6-4b96-98ef-03d261c3b051",
   "metadata": {},
   "source": [
    "1. followers\n",
    "1. retweeted-by\n",
    "1. wall\n",
    "1. retweets\n",
    "1. emojis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc855355-2742-47b4-a166-194898ded55b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Episode 6\n",
    "# make the utils folder and get them from the repo\n",
    "# we will make folder for learners:\n",
    "# https://github.com/DocNow/twarc/tree/main/utils\n",
    "\n",
    "!python utils/wall.py raw_data/taxday.jsonl > output_data/taxday_wall.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76d86256-2a22-4031-9a3d-d76b0ba3f3e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# what does this do?\n",
    "# it shows the tweet ID's of the Retweets in your dataset, and how much\n",
    "!python utils/retweets.py raw_data/taxday.jsonl > output_data/taxday_retweets.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceb74589-f708-4ab5-9a2b-00c2478d4020",
   "metadata": {},
   "outputs": [],
   "source": [
    "# how much is that?\n",
    "tax_retweets_df = pandas.read_csv(\"output_data/taxday_retweets.csv\", names=[\"tweetid\", \"retweets\"])\n",
    "tax_retweets_df.head()\n",
    "tax_retweets_df[\"retweets\"].plot(kind = \"hist\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "371d1385-a265-4e0b-a36f-064a9b5ac444",
   "metadata": {},
   "outputs": [],
   "source": [
    "retweet_total = sum(tax_retweets_df[\"retweets\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a974343-f4c3-4e3c-99c7-67d975cea76b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tax_retweets_df[\"retweets\"].plot(kind = \"hist\", loglog=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c5bbf73-444b-41a2-a72c-deb388217096",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TextBlob needs a string, so this won't work.\n",
    "TextBlob(kittens_df).sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d6da4f1-7a9a-47ef-a5ce-d4e5a3920752",
   "metadata": {},
   "source": [
    "# Episode 7: Search and Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afb13818-26a5-4d6a-bcf1-f99b3d7c966c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use Twitter advanced search syntax (everthing in quotes!)\n",
    "# to get tailored results\n",
    "!twarc2 search --limit 800 \"(cute OR fluffy OR haircut) (#catsofinstagram) lang:en\" kittens.jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec3cfcd-55cb-4434-b633-b548cb321141",
   "metadata": {},
   "outputs": [],
   "source": [
    "kittens_df = pandas.read_csv(\"output_data/kittens.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c8aa01-430a-4599-a65d-aaac822ff8c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "kittens_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0015b8ec-3e79-46d8-8f76-9aa7c5dc66b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(kittens_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a264ec5-4174-4e62-a3cd-9e16aef94059",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0edf38c5-f6b4-475d-9a2f-ffef08430159",
   "metadata": {},
   "source": [
    "# Episode 8: Analysis Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ccc6de7-126c-4975-8f1e-cacd1140ff34",
   "metadata": {},
   "outputs": [],
   "source": [
    "built-in should come first"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6c3b41d-cfc2-4a41-b710-4145d2fbb0af",
   "metadata": {},
   "source": [
    "### Sentiment Analysis\n",
    "To do this, we need to do a little Python\n",
    "\n",
    "TextBlob is a text processing library that does sentiment analysis. \n",
    "The sentiment property returns a namedtuple of the form Sentiment(polarity, subjectivity). The polarity score is a float within the range [-1.0, 1.0]. The subjectivity is a float within the range [0.0, 1.0] where 0.0 is very objective and 1.0 is very subjective."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd4d69fd-adcc-46a6-9a46-83cb991e52b9",
   "metadata": {},
   "source": [
    "Before we use TextBlob for sentiment analysis, we need to download\n",
    "datasets of words and their associated weights. These are called *corpora*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "423c7d9b-b67d-4b13-8894-75a64654b52d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m textblob.download_corpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6874ca27-b81f-4f4f-911b-68e9fe21384e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# break tweets test column into a list, then .join into one long string \n",
    "kittens_string = ' '.join(kittens_df['text'].tolist())\n",
    "# turn the string into a blob\n",
    "kittens_blob = TextBlob(kittens_string)\n",
    "# get the sentiment\n",
    "kittens_blob.sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "005ba8f5-5054-4fba-8e12-0bade66f4775",
   "metadata": {
    "tags": []
   },
   "source": [
    "The overall sentiment of the language of our kittens tweets is rather positive.\n",
    "And the tweets tend to be subjective."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f7f70c-b9ee-45cf-ad37-7a26cc43d559",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What do you think the sentiment of tax day might be?\n",
    "# get the overall sentiment and see if it matches your prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9856bda0-b290-40a0-ad22-32ece206312b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e03d25-b2af-4102-a418-b6b0532e0aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Episode 9: Data Management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e793dcc-20ec-419e-baab-4b75b308ba0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Episode 10: Don't Map Twitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d4e4d3d-71a6-4fe7-8b30-542ea123b4ad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
