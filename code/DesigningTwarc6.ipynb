{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "744056f4-ef73-4c90-a7bc-aef8167fd1cc",
   "metadata": {},
   "source": [
    "# Twitter with twarc\n",
    "A UCSB Carpentry workshop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1324c4e6-ab87-441e-bd4e-860eec5ccfe8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "35e9818e-0cc6-474e-b92b-28467ca18d4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: twarc-csv in /opt/conda/lib/python3.9/site-packages (0.5.2)\n",
      "Requirement already satisfied: more-itertools>=8.7.0 in /opt/conda/lib/python3.9/site-packages (from twarc-csv) (8.13.0)\n",
      "Requirement already satisfied: pandas>=1.2.5 in /opt/conda/lib/python3.9/site-packages (from twarc-csv) (1.4.2)\n",
      "Requirement already satisfied: twarc>=2.9.5 in /opt/conda/lib/python3.9/site-packages (from twarc-csv) (2.10.4)\n",
      "Requirement already satisfied: tqdm>=4.59.0 in /opt/conda/lib/python3.9/site-packages (from twarc-csv) (4.64.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /opt/conda/lib/python3.9/site-packages (from pandas>=1.2.5->twarc-csv) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.9/site-packages (from pandas>=1.2.5->twarc-csv) (2022.1)\n",
      "Requirement already satisfied: numpy>=1.18.5 in /opt/conda/lib/python3.9/site-packages (from pandas>=1.2.5->twarc-csv) (1.22.3)\n",
      "Requirement already satisfied: click-config-file>=0.6 in /opt/conda/lib/python3.9/site-packages (from twarc>=2.9.5->twarc-csv) (0.6.0)\n",
      "Requirement already satisfied: requests-oauthlib>=1.3 in /opt/conda/lib/python3.9/site-packages (from twarc>=2.9.5->twarc-csv) (1.3.1)\n",
      "Requirement already satisfied: humanize>=3.9 in /opt/conda/lib/python3.9/site-packages (from twarc>=2.9.5->twarc-csv) (4.1.0)\n",
      "Requirement already satisfied: click-plugins>=1 in /opt/conda/lib/python3.9/site-packages (from twarc>=2.9.5->twarc-csv) (1.1.1)\n",
      "Requirement already satisfied: click<9,>=7 in /opt/conda/lib/python3.9/site-packages (from twarc>=2.9.5->twarc-csv) (8.1.3)\n",
      "Requirement already satisfied: configobj>=5.0.6 in /opt/conda/lib/python3.9/site-packages (from click-config-file>=0.6->twarc>=2.9.5->twarc-csv) (5.0.6)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.9/site-packages (from python-dateutil>=2.8.1->pandas>=1.2.5->twarc-csv) (1.16.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.9/site-packages (from requests-oauthlib>=1.3->twarc>=2.9.5->twarc-csv) (3.2.0)\n",
      "Requirement already satisfied: requests>=2.0.0 in /opt/conda/lib/python3.9/site-packages (from requests-oauthlib>=1.3->twarc>=2.9.5->twarc-csv) (2.27.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.9/site-packages (from requests>=2.0.0->requests-oauthlib>=1.3->twarc>=2.9.5->twarc-csv) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.9/site-packages (from requests>=2.0.0->requests-oauthlib>=1.3->twarc>=2.9.5->twarc-csv) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.9/site-packages (from requests>=2.0.0->requests-oauthlib>=1.3->twarc>=2.9.5->twarc-csv) (2.0.12)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.9/site-packages (from requests>=2.0.0->requests-oauthlib>=1.3->twarc>=2.9.5->twarc-csv) (1.26.9)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# administravia\n",
    "# upon re-start we need to install twarc2 extensions\n",
    "! pip install twarc-csv\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2b8339f-952b-498f-bc0f-a5eda41a38e0",
   "metadata": {},
   "source": [
    "# Episode 2\n",
    "You should have a taxday.jsonl file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cbf7282-bf3d-4a51-ad72-008ccaef1a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BASH commands start with a BANG!\n",
    "!twarc2 --help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "d2ad701f-463e-40f9-958b-a09721e263d4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#  what libraries will we need to be loading in our notebook?\n",
    "#  we need to always distinguish between \n",
    "#  running BASH vs. running a line of python.\n",
    "\n",
    "import pandas\n",
    "import twarc_csv\n",
    "import textblob\n",
    "import nltk\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2082bb24-2751-406c-a918-c8c41d14e7b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# and of course, it's important to know where we are working\n",
    "# I can send a BASH command from my notebook with a !:\n",
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8098e978-172e-4949-a531-1a05fa43be25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can also do this with Python\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc19b894-b858-4966-ae5e-e32bff6bde2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure we are in the tward_run folder\n",
    "os.chdir(\"twarc_run\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17a6e89d-7e91-4558-ae3f-aa1026554cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbcb8c10-7fe2-4d91-bc0a-7267ec5062cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Let's look at a tweet\n",
    "!twarc2 csv raw_data/one_tweet.jsonl output_data/one_tweet.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5913eea7-a65c-4505-b1c5-a846d7a98d23",
   "metadata": {},
   "source": [
    "## Running twarc\n",
    "Let's get the timeline of one of twarc's creators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7dc0ce9-22df-449d-863c-7bff77889860",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "222e98bb-b6fa-442e-b1e9-5f5b72e518e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!twarc2 timeline BergisJules > raw_data/bjules.jsonl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4473db7c-3651-45f7-8c14-0f49b6c5c0f4",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Challenge 1\n",
    "- Can you find the file called “bjules.jsonl”?\n",
    "- What's the timestamp on the first one. The last one?\n",
    "\n",
    "- How many tweets did you get from Bergis? (we can't tell without flattening)\n",
    "- Download a timeline for a person of your choice. How many tweets did you get? \n",
    "- What’s the oldest one?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08892a04-a2be-4353-b64c-43a628e5ae50",
   "metadata": {},
   "source": [
    "## Flatten and convert to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf04f84-943a-4d7b-a45e-d007e6b5abc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "!twarc2 flatten raw_data/bjules.jsonl output_data/bjules_flattened.jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b29144d-a627-4128-b54f-74439f37a917",
   "metadata": {},
   "outputs": [],
   "source": [
    "!twarc2 csv raw_data/bjules.jsonl output_data/bjules.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab10779-cc96-4ed0-9e47-2e8faac15d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "!twarc2 flatten raw_data/ecodatasci.jsonl > output_data/ecodatasci_flattened.jsonl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2316f7fe-1614-404c-9516-897fd6415a7b",
   "metadata": {},
   "source": [
    "### Challenge 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1284486c-4487-401d-b421-20c4597dfedd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# commented line is a solution to challenge 1\n",
    "# !twarc2 timeline ecodatasci > raw_data/ecodatasci.jsonl\n",
    "\n",
    "!twarc2 csv output_data/ecodatasci_flattened.jsonl > output_data/ecodatasci.csv \n",
    "ecodatasci_df = pandas.read_csv(\"output_data/ecodatasci.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aecabff-dbda-4c8c-addc-a7132c3df302",
   "metadata": {},
   "outputs": [],
   "source": [
    "!twarc2 flatten raw_data/ecodatasci.jsonl > output_data/ecodatasci_flattened.jsonl\n",
    "!twarc2 csv output_data/ecodatasci_flattened.jsonl > output_data/ecodatasci.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbfccda8-2a25-44a3-bb9a-5bdbc2c6d6cb",
   "metadata": {},
   "source": [
    "# Episode 3: examining tweets\n",
    "What comes along with a tweet\n",
    "- Look at one_tweet in Jupyter viewer\n",
    "- Look at one_tweet with "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba9ab04-d27d-42bd-9a60-9f3a7198cff8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "99766d53-53ea-4ef2-b201-2e58c89d411d",
   "metadata": {},
   "source": [
    "## To flatten or not flatten"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "586f4cbf-4741-44e2-a025-9968faf74e77",
   "metadata": {},
   "source": [
    "### Make your jsonl 1 tweet per line\n",
    "This will let you do our most basic unix-y analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b7bd894-4995-4851-8668-983c3c4c9f35",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!wc raw_data/taxday.jsonl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bbe2b98-3264-45bc-adc0-f6aa567718cd",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Try again\n",
    "33 lines doesn't mean 33 tweets. I suspected there was more there becauce\n",
    "I got an error message about hitting a limit of 3200. \n",
    "\n",
    "We need to either flatten our tweets, or convert them\n",
    "to a csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1dc091e-8fb8-49ab-b6d5-58e454d4bc90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# flatten\n",
    "!twarc2 flatten raw_data/taxday.jsonl output_data/taxday_flattened.jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd5bd6d9-24f4-4a93-9222-1dad58059328",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wc output_data/taxday_flattened.jsonl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a8c4d85-fa2a-4e7d-9e7c-1fa1207d64fc",
   "metadata": {},
   "source": [
    "## When we look at bjules, we really do need to flatten it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9015236-250a-4f85-83b0-296431fe65a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert\n",
    "!twarc2 csv raw_data/bjules.jsonl output_data/bjules.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "180e3158-2f08-4d08-8e9e-b4ab999e6ef1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# When I did this, I got 3166 tweets (as opposed to the 33 lines that the original file was)\n",
    "! wc output_data/bjules_flattened.jsonl\n",
    "! wc output_data/bjules.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d55e1a66-f173-4adb-898c-572f15c7bbcb",
   "metadata": {},
   "source": [
    "The csv is 1 line longer because it has column headers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab4c78d8-42bd-458c-b618-d1c854fc265f",
   "metadata": {},
   "source": [
    "Can we go back further on his timeline by looking\n",
    "only for Bergis's original content?\n",
    "\n",
    "No--the same limit applies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b29e6727-48e8-4c79-b824-fd109b0e7029",
   "metadata": {},
   "outputs": [],
   "source": [
    "!twarc2 timeline BergisJules --exclude-retweets --exclude-replies > raw_data/bjules_original"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ec876b9-c5b4-463a-8552-af4c0b97c446",
   "metadata": {},
   "source": [
    "Let's look at out taxday.jsonl file that we prepared for you on April 18."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c876b6-789d-408f-b164-bdd1f6aaddcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "!head -n 1 raw_data/taxday.jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f64d26-ae10-4deb-bf48-47f88b7db62f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6efcdaf-a547-4a93-95d3-94e4bfcdddff",
   "metadata": {},
   "outputs": [],
   "source": [
    "!twarc2 flatten raw_data/bjules_original.jsonl output_data/bjules_original_flat.jsonl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a685310-f080-4ff8-8728-a46ca21f926b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e4a5ce0-373b-4106-8959-31850ae8fb17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A lot comes along! \n",
    "!tail -n 1 raw_data/taxday.jsonl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e89e3a4e-4955-426a-9081-1ea9739304c9",
   "metadata": {},
   "source": [
    "## Challenge: tax day Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d95d44-829c-431c-bd6c-7ee4b842506a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we harvested 3 hours worth of tweets for you on tax day.\n",
    "# how many tweets?\n",
    "!wc raw_data/taxday.jsonl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af2f2152-7de1-40d4-9d97-c6aa551ce2fd",
   "metadata": {},
   "source": [
    "## Next harvest\n",
    "Next we'll get just Bergis' original content. \n",
    "In other words, only the tweets that he wrote, not\n",
    "any retweets or replied to other people tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb6ab7f-2bb4-47d0-bfa8-acb7e9ad77ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e67c2f11-27b4-4802-9d94-19589291e94d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3310f048-6ad7-4ee6-bd4e-c727ec8031a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd90d6c-c9b9-41e5-ae9d-6b3c457cbc9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# maybe the last challenge for ep. 3 is examining this shorter file?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29ab11e8-f109-4670-912c-3122ea2b8211",
   "metadata": {},
   "source": [
    "# Episode 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "021f95fb-293d-459c-9afd-59d624efa865",
   "metadata": {},
   "outputs": [],
   "source": [
    "!twarc2 counts --granularity \"day\" --text \"(#UCSBLibrary OR UCSBLibrary OR ucsblibrary OR #ucsblibrary OR davidsonlibrary OR #davidsonlibrary)\"\n",
    "# is it worth doing the OR's? For sure.\n",
    "!twarc2 counts --granularity \"day\" --text \"(#UCSBLibrary OR UCSBLibrary)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be3bd639-6118-4983-bb16-1ff7fd3999de",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Endpoints: counts\n",
    "!twarc2 counts --text \"(Poker OR poker)\" --granularity \"day\"\n",
    "!twarc2 counts --text \"(Golf OR golf)\" --granularity \"day\"\n",
    "!twarc2 counts --text \"(Basketball OR basketball)\" --granularity \"day\"\n",
    "!twarc2 counts --text \"(Baseball OR baseball)\" --granularity \"day\"\n",
    "!twarc2 counts --text \"(Football OR football)\" --granularity \"day\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5443c1c7-0da2-4ad9-82fd-1e9b2b377a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "## What's a lot?\n",
    "!twarc2 counts --text \"dog\" --granularity \"day\"\n",
    "!twarc2 counts --text \"cat\" --granularity \"day\"\n",
    "!twarc2 counts --text \"amazon\" --granularity \"day\"\n",
    "!twarc2 counts --text \"right\" --granularity \"day\"\n",
    "!twarc2 counts --text \"good\" --granularity \"day\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b64d9fa-d4d2-49c3-bf09-1e3a9d0ab35b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc52493-cf69-4298-8617-515a581ead59",
   "metadata": {},
   "outputs": [],
   "source": [
    "## a SFW timeline\n",
    "# !twarc2 timeline ucsblibrary raw_data/library.jsonl\n",
    "!twarc2 flatten raw_data/library.jsonl output_data/library.jsonl\n",
    "!twarc2 csv output_data/library.jsonl output_data/library.csv\n",
    "library_df = pandas.read_csv(\"output_data/library.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc06081-ef7c-4122-b7c0-0901ca4a2dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# confirm the dataframe's existance\n",
    "list(library_df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5af9bd3-debf-4910-a2f1-30a760d599cd",
   "metadata": {},
   "source": [
    "### Converting to csv and dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44e2145d-a912-49ea-8044-544cb11bb38d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!twarc2 csv raw_data/taxday.jsonl output_data/taxday.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb2daed5-e882-4d66-bcdc-f403bb3a6710",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a492aa1b-dd0f-44f0-b0bc-dedec7d38b0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab6d14b4-0c5e-4553-9eb2-7d8d284476af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fishing around for good searches\n",
    "!twarc2 counts --text \"kittens\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee4cc6aa-8a09-4b27-9dab-0b80cf267fcc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "23735a74-0dd1-4483-9705-595042b099bc",
   "metadata": {},
   "source": [
    "## final challenge: Cats of Instagram\n",
    "Let’s make a bigger datafile. Harvest 5000 tweets that use the hashtag “catsofinstagram” and put the dataset through the pipeline to answer the following questions:\n",
    "\n",
    "- Did you get exactly 5000?\n",
    "- How far back in time did you get?\n",
    "- What is the most re-tweeted recent tweet on #catsofinstagram?\n",
    "- Which person has the most number of followers in your dataset?\n",
    "- Is it really a person?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a68cc58-0dc5-4255-92f5-0e220b7385ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "!twarc2 search --limit 500 \"#catsofinstagram\" hashtagcats.jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "952eed26-010f-464b-82c9-4699988555b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "!twarc2 search --limit 5000 \"#catsofinstagram\" raw_data/hashtagcats.jsonl\n",
    "!twarc2 csv raw_data/hashtagcats.jsonl > output_data/hashtag_cats.csv\n",
    "hashtag_cats_df = pandas.read_csv(\"output_data/hashtag_cats.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c151b25e-f551-445c-93ed-118406e3df40",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(hashtag_cats_df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "870d9fb7-03eb-4dcd-9ab8-d4888b008f65",
   "metadata": {},
   "source": [
    "# Episode 5: Ethics & Twitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03843c37-975f-44f6-8ab9-459055477e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# emojis as proxies for text\n",
    "# run the built-in emoji counter/printer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "f046b945-b698-4c9b-b6c4-8047382f16aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# our first full-text analysis\n",
    "# a list of words with TextBlob\n",
    "\n",
    "# first we need to munge the data. remember from:\n",
    "# list(library_df.columns)\n",
    "# the tweet is library_df['text']\n",
    "\n",
    "# TextBlob has its own data format.\n",
    "\n",
    "# break tweets test column into a list, \n",
    "# then .join into one long string \n",
    "library_string = ' '.join(library_df['text'].tolist())\n",
    "# turn the string into a blob\n",
    "library_blob = TextBlob(library_string)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4522956e-9332-4219-a21b-7e2dfbf3bc02",
   "metadata": {},
   "source": [
    "This produces a mess. we need to filter out the hyperlinks and stop words. And how about a phrase counter?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a5a3b36-fffd-477c-91bb-cdf315dbe285",
   "metadata": {},
   "outputs": [],
   "source": [
    "library_freq = library_blob.word_counts\n",
    "library_sorted_freq = sorted(library_freq.items(), \n",
    "                             key = lambda kv: kv[1], \n",
    "                             reverse = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "0ebad179-03a4-4f7d-aaf8-7fb366dddd77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# can I just do the first bunch?\n",
    "type(library_sorted_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "a69badc7-8fa2-4bd1-b556-ff28318f8642",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('https', 2280),\n",
       " ('to', 1644),\n",
       " ('of', 1523),\n",
       " ('and', 1241),\n",
       " ('ucsb', 1147),\n",
       " ('http', 1118),\n",
       " ('in', 1104),\n",
       " ('library', 1070),\n",
       " ('a', 1049),\n",
       " ('for', 1009),\n",
       " ('s', 744),\n",
       " ('on', 671),\n",
       " ('at', 632),\n",
       " ('you', 604),\n",
       " ('our', 547),\n",
       " ('we', 531),\n",
       " ('is', 500),\n",
       " ('from', 475),\n",
       " ('this', 452),\n",
       " ('ucsblibrary', 415),\n",
       " ('by', 391),\n",
       " ('with', 391),\n",
       " ('amp', 330),\n",
       " ('more', 326)]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "library_sorted_freq[1:25]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfa676be-7ceb-45e8-82e8-7429b8884d7b",
   "metadata": {},
   "source": [
    "We can at least get the english stopwords out. but this all didn't reall produce anything cleaner:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "b5cd1c12-d78a-44e5-9376-26b4a0589785",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "sw_nltk = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "e878e6b7-2c29-45e8-83cd-fb0eefd3b668",
   "metadata": {},
   "outputs": [],
   "source": [
    "library_str_stopped = [word for word in library_string.split() \n",
    "                       if word.lower() not in sw_nltk]\n",
    "stopped_text = \" \".join(library_str_stopped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e27a5b1-0519-407c-ae52-abd0587857a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "library_blob_stopped = TextBlob(stopped_text)\n",
    "library_blob_stopped_freq = library_blob_stopped.word_counts\n",
    "library_blob_stopped_sorted_freq = sorted(library_blob_stopped_freq.items(), \n",
    "                             key = lambda kv: kv[1], \n",
    "                             reverse = True)\n",
    "library_blob_stopped_sorted_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "9b658645-2144-45c0-9d76-bac57357e9de",
   "metadata": {},
   "outputs": [],
   "source": [
    "library_stopped_blob = [word for word in library_blob.split()\n",
    "                        if word.lower() not in sw_nltk]\n",
    "new_text = \" \".join(library_stopped_blob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "c343fbf8-241c-4ec7-8b6e-da4c3db73717",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(library_stopped_blob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e074d32e-4a94-4add-89b3-cf0863340cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Challenge: for the Python wizzes.\n",
    "# do that in a tidy way?\n",
    "# what do pandas pipes look like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3929ae1c-4a37-4cef-9501-7fc2b540f513",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e99fdaca-edb7-41f1-b35c-a82092579ee0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2bc9aad4-1981-4911-ac2e-18bb3b0e92ae",
   "metadata": {},
   "source": [
    "## Challenge: Insta-rrectionists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe5551d5-4b64-4731-9285-82bfc5fd9a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "!twarc2 hydrate raw_data/dehydratedCapitolRiotTweets.txt output_data/riots.jsonl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76119af0-f58e-4bb4-a296-f0718b28a05b",
   "metadata": {},
   "outputs": [],
   "source": [
    "riots_dehydrated_df = pandas.read_csv(\"raw_data/dehydratedCapitolRiotTweets.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae63a6f5-71af-4a07-a940-d96b45ebd1a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "12ca8fc4-ac95-4535-8146-843e2126e915",
   "metadata": {},
   "source": [
    "# Episode 6: Working with our Tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e70e7058-cdc6-4b96-98ef-03d261c3b051",
   "metadata": {},
   "source": [
    "1. followers\n",
    "1. retweeted-by\n",
    "1. wall\n",
    "1. retweets\n",
    "1. emojis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc855355-2742-47b4-a166-194898ded55b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Episode 6\n",
    "# make the utils folder and get them from the repo\n",
    "# we will make folder for learners:\n",
    "# https://github.com/DocNow/twarc/tree/main/utils\n",
    "\n",
    "!python utils/wall.py raw_data/taxday.jsonl > output_data/taxday_wall.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76d86256-2a22-4031-9a3d-d76b0ba3f3e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# what does this do?\n",
    "# it shows the tweet ID's of the Retweets in your dataset, and how much\n",
    "!python utils/retweets.py raw_data/taxday.jsonl > output_data/taxday_retweets.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceb74589-f708-4ab5-9a2b-00c2478d4020",
   "metadata": {},
   "outputs": [],
   "source": [
    "# how much is that?\n",
    "tax_retweets_df = pandas.read_csv(\"output_data/taxday_retweets.csv\", names=[\"tweetid\", \"retweets\"])\n",
    "tax_retweets_df.head()\n",
    "tax_retweets_df[\"retweets\"].plot(kind = \"hist\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "371d1385-a265-4e0b-a36f-064a9b5ac444",
   "metadata": {},
   "outputs": [],
   "source": [
    "retweet_total = sum(tax_retweets_df[\"retweets\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a974343-f4c3-4e3c-99c7-67d975cea76b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tax_retweets_df[\"retweets\"].plot(kind = \"hist\", loglog=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c5bbf73-444b-41a2-a72c-deb388217096",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TextBlob needs a string, so this won't work.\n",
    "TextBlob(kittens_df).sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d6da4f1-7a9a-47ef-a5ce-d4e5a3920752",
   "metadata": {},
   "source": [
    "# Episode 7: Search and Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afb13818-26a5-4d6a-bcf1-f99b3d7c966c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use Twitter advanced search syntax (everthing in quotes!)\n",
    "# to get tailored results\n",
    "!twarc2 search --limit 800 \"(cute OR fluffy OR haircut) (#catsofinstagram) lang:en\" kittens.jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec3cfcd-55cb-4434-b633-b548cb321141",
   "metadata": {},
   "outputs": [],
   "source": [
    "kittens_df = pandas.read_csv(\"output_data/kittens.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c8aa01-430a-4599-a65d-aaac822ff8c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "kittens_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0015b8ec-3e79-46d8-8f76-9aa7c5dc66b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(kittens_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a264ec5-4174-4e62-a3cd-9e16aef94059",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0edf38c5-f6b4-475d-9a2f-ffef08430159",
   "metadata": {},
   "source": [
    "# Episode 8: Analysis Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ccc6de7-126c-4975-8f1e-cacd1140ff34",
   "metadata": {},
   "outputs": [],
   "source": [
    "built-in should come first"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6c3b41d-cfc2-4a41-b710-4145d2fbb0af",
   "metadata": {},
   "source": [
    "### Sentiment Analysis\n",
    "To do this, we need to do a little Python\n",
    "\n",
    "TextBlob is a text processing library that does sentiment analysis. \n",
    "The sentiment property returns a namedtuple of the form Sentiment(polarity, subjectivity). The polarity score is a float within the range [-1.0, 1.0]. The subjectivity is a float within the range [0.0, 1.0] where 0.0 is very objective and 1.0 is very subjective."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd4d69fd-adcc-46a6-9a46-83cb991e52b9",
   "metadata": {},
   "source": [
    "Before we use TextBlob for sentiment analysis, we need to download\n",
    "datasets of words and their associated weights. These are called *corpora*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "423c7d9b-b67d-4b13-8894-75a64654b52d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m textblob.download_corpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6874ca27-b81f-4f4f-911b-68e9fe21384e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# break tweets test column into a list, then .join into one long string \n",
    "kittens_string = ' '.join(kittens_df['text'].tolist())\n",
    "# turn the string into a blob\n",
    "kittens_blob = TextBlob(kittens_string)\n",
    "# get the sentiment\n",
    "kittens_blob.sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "005ba8f5-5054-4fba-8e12-0bade66f4775",
   "metadata": {
    "tags": []
   },
   "source": [
    "The overall sentiment of the language of our kittens tweets is rather positive.\n",
    "And the tweets tend to be subjective."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f7f70c-b9ee-45cf-ad37-7a26cc43d559",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What do you think the sentiment of tax day might be?\n",
    "# get the overall sentiment and see if it matches your prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9856bda0-b290-40a0-ad22-32ece206312b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e03d25-b2af-4102-a418-b6b0532e0aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Episode 9: Data Management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e793dcc-20ec-419e-baab-4b75b308ba0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Episode 10: Don't Map Twitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d4e4d3d-71a6-4fe7-8b30-542ea123b4ad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
