{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3b8988ea-176a-42c1-9826-2c125aba3a5e",
   "metadata": {},
   "source": [
    "# Twitter with twarc\n",
    "A UCSB origihnal Carpentry workshop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1324c4e6-ab87-441e-bd4e-860eec5ccfe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this version generally has calls to the twitter api commented\n",
    "# out to preserve quotas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "35e9818e-0cc6-474e-b92b-28467ca18d4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: twarc-csv in /opt/conda/lib/python3.9/site-packages (0.5.2)\n",
      "Requirement already satisfied: tqdm>=4.59.0 in /opt/conda/lib/python3.9/site-packages (from twarc-csv) (4.64.0)\n",
      "Requirement already satisfied: pandas>=1.2.5 in /opt/conda/lib/python3.9/site-packages (from twarc-csv) (1.4.2)\n",
      "Requirement already satisfied: twarc>=2.9.5 in /opt/conda/lib/python3.9/site-packages (from twarc-csv) (2.10.4)\n",
      "Requirement already satisfied: more-itertools>=8.7.0 in /opt/conda/lib/python3.9/site-packages (from twarc-csv) (8.13.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /opt/conda/lib/python3.9/site-packages (from pandas>=1.2.5->twarc-csv) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.9/site-packages (from pandas>=1.2.5->twarc-csv) (2022.1)\n",
      "Requirement already satisfied: numpy>=1.18.5 in /opt/conda/lib/python3.9/site-packages (from pandas>=1.2.5->twarc-csv) (1.22.3)\n",
      "Requirement already satisfied: humanize>=3.9 in /opt/conda/lib/python3.9/site-packages (from twarc>=2.9.5->twarc-csv) (4.1.0)\n",
      "Requirement already satisfied: click-config-file>=0.6 in /opt/conda/lib/python3.9/site-packages (from twarc>=2.9.5->twarc-csv) (0.6.0)\n",
      "Requirement already satisfied: click-plugins>=1 in /opt/conda/lib/python3.9/site-packages (from twarc>=2.9.5->twarc-csv) (1.1.1)\n",
      "Requirement already satisfied: requests-oauthlib>=1.3 in /opt/conda/lib/python3.9/site-packages (from twarc>=2.9.5->twarc-csv) (1.3.1)\n",
      "Requirement already satisfied: click<9,>=7 in /opt/conda/lib/python3.9/site-packages (from twarc>=2.9.5->twarc-csv) (8.1.3)\n",
      "Requirement already satisfied: configobj>=5.0.6 in /opt/conda/lib/python3.9/site-packages (from click-config-file>=0.6->twarc>=2.9.5->twarc-csv) (5.0.6)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.9/site-packages (from python-dateutil>=2.8.1->pandas>=1.2.5->twarc-csv) (1.16.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.9/site-packages (from requests-oauthlib>=1.3->twarc>=2.9.5->twarc-csv) (3.2.0)\n",
      "Requirement already satisfied: requests>=2.0.0 in /opt/conda/lib/python3.9/site-packages (from requests-oauthlib>=1.3->twarc>=2.9.5->twarc-csv) (2.27.1)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.9/site-packages (from requests>=2.0.0->requests-oauthlib>=1.3->twarc>=2.9.5->twarc-csv) (2.0.12)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.9/site-packages (from requests>=2.0.0->requests-oauthlib>=1.3->twarc>=2.9.5->twarc-csv) (1.26.9)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.9/site-packages (from requests>=2.0.0->requests-oauthlib>=1.3->twarc>=2.9.5->twarc-csv) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.9/site-packages (from requests>=2.0.0->requests-oauthlib>=1.3->twarc>=2.9.5->twarc-csv) (2021.10.8)\n",
      "Requirement already satisfied: emoji in /opt/conda/lib/python3.9/site-packages (1.7.0)\n"
     ]
    }
   ],
   "source": [
    "# administravia\n",
    "# upon re-start we need to install twarc2 extensions\n",
    "! pip install twarc-csv\n",
    "! pip install emoji"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2b8339f-952b-498f-bc0f-a5eda41a38e0",
   "metadata": {},
   "source": [
    "# Episode 2\n",
    "You should have a taxday.jsonl file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3cbf7282-bf3d-4a51-ad72-008ccaef1a13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usage: twarc2 [OPTIONS] COMMAND [ARGS]...\n",
      "\n",
      "  Collect data from the Twitter V2 API.\n",
      "\n",
      "Options:\n",
      "  --consumer-key TEXT         Twitter app consumer key (aka \"App Key\")\n",
      "  --consumer-secret TEXT      Twitter app consumer secret (aka \"App Secret\")\n",
      "  --access-token TEXT         Twitter app access token for user\n",
      "                              authentication.\n",
      "  --access-token-secret TEXT  Twitter app access token secret for user\n",
      "                              authentication.\n",
      "  --bearer-token TEXT         Twitter app access bearer token.\n",
      "  --app-auth / --user-auth    Use application authentication or user\n",
      "                              authentication. Some rate limits are higher with\n",
      "                              user authentication, but not all endpoints are\n",
      "                              supported.  [default: app-auth]\n",
      "  -l, --log TEXT\n",
      "  --verbose\n",
      "  --metadata / --no-metadata  Include/don't include metadata about when and\n",
      "                              how data was collected.  [default: metadata]\n",
      "  --config FILE               Read configuration from FILE.\n",
      "  --help                      Show this message and exit.\n",
      "\n",
      "Commands:\n",
      "  compliance-job  Create, retrieve and list batch compliance jobs for...\n",
      "  configure       Set up your Twitter app keys.\n",
      "  conversation    Retrieve a conversation thread using the tweet id.\n",
      "  conversations   Fetch the full conversation threads that the input...\n",
      "  counts          Return counts of tweets matching a query.\n",
      "  csv             Convert tweets to CSV.\n",
      "  dehydrate       Extract tweet or user IDs from a dataset.\n",
      "  flatten         \"Flatten\" tweets, or move expansions inline with tweet...\n",
      "  followers       Get the followers for a given user.\n",
      "  following       Get the users that a given user is following.\n",
      "  hydrate         Hydrate tweet ids.\n",
      "  liked-tweets    Get the tweets liked by a specific user_id.\n",
      "  liking-users    Get the users that liked a specific tweet.\n",
      "  lists           Lists API support.\n",
      "  mentions        Retrieve max of 800 of the most recent tweets...\n",
      "  places          Search for places by place name, geo coordinates or ip...\n",
      "  quotes          Get the tweets that quote tweet the given tweet.\n",
      "  retweeted-by    Get the users that retweeted a specific tweet.\n",
      "  sample          Fetch tweets from the sample stream.\n",
      "  search          Search for tweets.\n",
      "  searches        Execute each search in the input file, one at a time.\n",
      "  stream          Fetch tweets from the live stream.\n",
      "  stream-rules    List, add and delete rules for your stream.\n",
      "  timeline        Retrieve recent tweets for the given user.\n",
      "  timelines       Fetch the timelines of every user in an input source of...\n",
      "  tweet           Look up a tweet using its tweet id or URL.\n",
      "  user            Get the profile data for a single user by either...\n",
      "  users           Get data for user ids or usernames.\n",
      "  version         Return the version of twarc that is installed.\n"
     ]
    }
   ],
   "source": [
    "# BASH commands start with a BANG!\n",
    "!twarc2 --help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d2ad701f-463e-40f9-958b-a09721e263d4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "#  what libraries will we need to be loading in our notebook?\n",
    "#  we need to always distinguish between \n",
    "#  running BASH vs. running a line of python.\n",
    "\n",
    "import pandas\n",
    "import twarc_csv\n",
    "import textblob\n",
    "import nltk\n",
    "import os\n",
    "import emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "df5f4739-6651-4fad-b521-190e8aa0028b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package brown to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package brown is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package conll2000 to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package conll2000 is already up-to-date!\n",
      "[nltk_data] Downloading package movie_reviews to\n",
      "[nltk_data]     /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package movie_reviews is already up-to-date!\n",
      "Finished.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this comes into play for ep 8\n",
    "!python -m textblob.download_corpora\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2082bb24-2751-406c-a918-c8c41d14e7b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jovyan/twarc_run\n"
     ]
    }
   ],
   "source": [
    "# and of course, it's important to know where we are working\n",
    "# I can send a BASH command from my notebook with a !:\n",
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8098e978-172e-4949-a531-1a05fa43be25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can also do this with Python\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc19b894-b858-4966-ae5e-e32bff6bde2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure we are in the twarc_run folder\n",
    "os.chdir(\"twarc_run\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17a6e89d-7e91-4558-ae3f-aa1026554cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5913eea7-a65c-4505-b1c5-a846d7a98d23",
   "metadata": {},
   "source": [
    "## Running twarc\n",
    "Let's get the timeline of one of twarc's creators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "222e98bb-b6fa-442e-b1e9-5f5b72e518e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !twarc2 timeline BergisJules > raw_data/bjules.jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eaf04f84-943a-4d7b-a45e-d007e6b5abc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████████| Processed 8.95M/8.95M of input file [00:00<00:00, 10.1MB/s]\n"
     ]
    }
   ],
   "source": [
    "# timeline objects need to be flattened in order to be analyzed as tweets\n",
    "!twarc2 flatten raw_data/bjules.jsonl output_data/bjules_flat.jsonl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4473db7c-3651-45f7-8c14-0f49b6c5c0f4",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Challenge 1\n",
    "- Can you find the file called “bjules_flat.jsonl”?\n",
    "- What's the timestamp on the first one. The last one?\n",
    "\n",
    "- How many tweets did you get from Bergis? (we can't tell without flattening)\n",
    "- Download a timeline for a person of your choice. How many tweets did you get? \n",
    "- What’s the oldest one?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bab10779-cc96-4ed0-9e47-2e8faac15d93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    473  204893 2875654 output_data/ecodatasci_flat.jsonl\n"
     ]
    }
   ],
   "source": [
    "!twarc2 flatten raw_data/ecodatasci.jsonl > output_data/ecodatasci_flat.jsonl\n",
    "!wc output_data/ecodatasci_flat.jsonl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08892a04-a2be-4353-b64c-43a628e5ae50",
   "metadata": {},
   "source": [
    "## Convert to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1b29144d-a627-4128-b54f-74439f37a917",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████████| Processed 8.95M/8.95M of input file [00:02<00:00, 3.62MB/s]\n",
      "\n",
      "ℹ️\n",
      "Parsed 3140 tweets objects from 33 lines in the input file.\n",
      "Wrote 3140 rows and output 74 columns in the CSV.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!twarc2 csv raw_data/bjules.jsonl output_data/bjules.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2316f7fe-1614-404c-9516-897fd6415a7b",
   "metadata": {},
   "source": [
    "### Challenge 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1284486c-4487-401d-b421-20c4597dfedd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# commented line is a solution to challenge 1\n",
    "# !twarc2 timeline ecodatasci > raw_data/ecodatasci.jsonl\n",
    "\n",
    "!twarc2 flatten raw_data/ecodatasci.jsonl > output_data/ecodatasci_flat.jsonl\n",
    "!twarc2 csv output_data/ecodatasci_flat.jsonl > output_data/ecodatasci.csv \n",
    "ecodatasci_df = pandas.read_csv(\"output_data/ecodatasci.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f31b31-3360-4d6f-84b4-0db227a1a335",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bbfccda8-2a25-44a3-bb9a-5bdbc2c6d6cb",
   "metadata": {},
   "source": [
    "# Episode 3: examining tweets\n",
    "What comes along with a tweet\n",
    "- Look at one_tweet in Jupyter viewer\n",
    "- Look at one_tweet with nano\n",
    "- Look at tweet as csv\n",
    "- Look at all the entities of a tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba9ab04-d27d-42bd-9a60-9f3a7198cff8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "99766d53-53ea-4ef2-b201-2e58c89d411d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## To flatten or not flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dbcb8c10-7fe2-4d91-bc0a-7267ec5062cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|█████████████████| Processed 299k/299k of input file [00:00<00:00, 134MB/s]\n",
      "\n",
      "ℹ️\n",
      "Parsed 0 tweets objects from 35 lines in the input file.\n",
      "\u001b[31m34 failed to parse. See twarc.log for details.\n",
      "\u001b[0mWrote 0 rows and output 74 columns in the CSV.\n",
      "\n",
      "  0%|                        | Processed 0.00/299k of input file [00:00<?, ?B/s]\n",
      "\u001b[33m⚡ \u001b[0m\u001b[31mExpecting property name enclosed in double quotes: line 2 column 1 (char 39)\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "### Let's look at a tweet as a csv:\n",
    "\n",
    "#this doesn't work\n",
    "!twarc2 csv raw_data/one_tweet.jsonl output_data/one_tweet.csv\n",
    "\n",
    "# it needs to be flattened before csv can be made?\n",
    "# but this also doesn't work:\n",
    "!twarc2 flatten raw_data/one_tweet.jsonl output_data/one_tweet_flat.jsonl\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b45c870f-a06f-45dd-a424-040d65aaa731",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "586f4cbf-4741-44e2-a025-9968faf74e77",
   "metadata": {},
   "source": [
    "### Make your jsonl 1 tweet per line\n",
    "Flattening will let you do our most basic unix-y analysis, turn\n",
    "timelines into countable lists, and enable you to run twarc1\n",
    "utilities later on in the workshop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7b7bd894-4995-4851-8668-983c3c4c9f35",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    15698   7653538 100048736 raw_data/taxday.jsonl\n"
     ]
    }
   ],
   "source": [
    "!wc raw_data/taxday.jsonl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bbe2b98-3264-45bc-adc0-f6aa567718cd",
   "metadata": {
    "tags": []
   },
   "source": [
    "A straight harvest using search or stream doesn't need to be flattened \n",
    "to do our most basic analysis: wc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b1dc091e-8fb8-49ab-b6d5-58e454d4bc90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████████| Processed 95.4M/95.4M of input file [00:03<00:00, 25.1MB/s]\n"
     ]
    }
   ],
   "source": [
    "# flatten\n",
    "!twarc2 flatten raw_data/taxday.jsonl output_data/taxday_flat.jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cd5bd6d9-24f4-4a93-9222-1dad58059328",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    15698   7653538 100048736 output_data/taxday_flat.jsonl\n"
     ]
    }
   ],
   "source": [
    "!wc output_data/taxday_flat.jsonl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "917b8a63-5c4b-45ae-9dae-4de8f6912d5e",
   "metadata": {},
   "source": [
    "For taxday, it doesn't seem to matter if we flatten or not"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a8c4d85-fa2a-4e7d-9e7c-1fa1207d64fc",
   "metadata": {},
   "source": [
    "## When we look at bjules, we really do need to flatten it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bfc7ab7b-7099-4213-bf10-0d2f6a1825d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     33  844925 9385982 raw_data/bjules.jsonl\n"
     ]
    }
   ],
   "source": [
    "! wc raw_data/bjules.jsonl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05ca8093-2fc9-4600-baa4-b1ba9d591d46",
   "metadata": {},
   "source": [
    "33 lines doesn't mean 33 tweets. I suspected there was more there because\n",
    "I got an error message about hitting a limit of 3200. \n",
    "\n",
    "And below, the csv converter tells us there are 3140 tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c9015236-250a-4f85-83b0-296431fe65a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████████| Processed 8.95M/8.95M of input file [00:02<00:00, 3.74MB/s]\n",
      "\n",
      "ℹ️\n",
      "Parsed 3140 tweets objects from 33 lines in the input file.\n",
      "Wrote 3140 rows and output 74 columns in the CSV.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# convert\n",
    "!twarc2 csv raw_data/bjules.jsonl output_data/bjules.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "180e3158-2f08-4d08-8e9e-b4ab999e6ef1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    3140  1717206 23260288 output_data/bjules_flat.jsonl\n"
     ]
    }
   ],
   "source": [
    "# When I did this, I got 3166 tweets (as opposed to the 33 lines that the original file was)\n",
    "! wc output_data/bjules_flat.jsonl\n",
    "# ! wc output_data/bjules.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d55e1a66-f173-4adb-898c-572f15c7bbcb",
   "metadata": {},
   "source": [
    "The csv is 1 line longer because it has column headers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af2f2152-7de1-40d4-9d97-c6aa551ce2fd",
   "metadata": {},
   "source": [
    "## Next harvest\n",
    "Next we'll get just Bergis' original content. \n",
    "In other words, only the tweets that he wrote, not\n",
    "any retweets or replied to other people tweets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab4c78d8-42bd-458c-b618-d1c854fc265f",
   "metadata": {},
   "source": [
    "Can we go back further on his timeline by looking\n",
    "only for Bergis's original content?\n",
    "\n",
    "Not really--it looks like the limit applies to the search,\n",
    "not the results. \n",
    "\n",
    "But this does tell us that Jules is a prolific re-tweeter and/or replier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b29e6727-48e8-4c79-b824-fd109b0e7029",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API limit of 3200 reached:   0%|             | 47/17680 [00:00<03:55, 74.85it/s]\n"
     ]
    }
   ],
   "source": [
    "!twarc2 timeline BergisJules --exclude-retweets --exclude-replies > raw_data/bjules_original.jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d6efcdaf-a547-4a93-95d3-94e4bfcdddff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|████████████████| Processed 107k/107k of input file [00:00<00:00, 25.2MB/s]\n"
     ]
    }
   ],
   "source": [
    "!twarc2 flatten raw_data/bjules_original.jsonl output_data/bjules_original_flat.jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d6f64d26-ae10-4deb-bf48-47f88b7db62f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|████████████████| Processed 234k/234k of input file [00:00<00:00, 7.64MB/s]\n",
      "\n",
      "ℹ️\n",
      "Parsed 47 tweets objects from 47 lines in the input file.\n",
      "Wrote 47 rows and output 74 columns in the CSV.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# save it as a csv so we can easily see the original writings of Jules\n",
    "!twarc2 csv output_data/bjules_original_flat.jsonl output_data/bjules_original.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ec876b9-c5b4-463a-8552-af4c0b97c446",
   "metadata": {},
   "source": [
    "Let's look at out taxday.jsonl file that we prepared for you on April 18."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c876b6-789d-408f-b164-bdd1f6aaddcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "!head -n 1 raw_data/taxday.jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a685310-f080-4ff8-8728-a46ca21f926b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e4a5ce0-373b-4106-8959-31850ae8fb17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A lot comes along! \n",
    "!tail -n 1 raw_data/taxday.jsonl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e89e3a4e-4955-426a-9081-1ea9739304c9",
   "metadata": {},
   "source": [
    "## Challenge: tax day Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "67d95d44-829c-431c-bd6c-7ee4b842506a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    15698   7653538 100048736 raw_data/taxday.jsonl\n",
      "    15698   7653538 100048736 output_data/taxday_flat.jsonl\n"
     ]
    }
   ],
   "source": [
    "# we harvested 3 hours worth of tweets for you on tax day.\n",
    "# how many tweets?\n",
    "!wc raw_data/taxday.jsonl\n",
    "!wc output_data/taxday_flat.jsonl\n",
    "# same number, so we don't have to flatten these."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb6ab7f-2bb4-47d0-bfa8-acb7e9ad77ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e67c2f11-27b4-4802-9d94-19589291e94d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3310f048-6ad7-4ee6-bd4e-c727ec8031a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd90d6c-c9b9-41e5-ae9d-6b3c457cbc9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# maybe the last challenge for ep. 3 is examining this shorter file?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29ab11e8-f109-4670-912c-3122ea2b8211",
   "metadata": {},
   "source": [
    "# Episode 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ab6d14b4-0c5e-4553-9eb2-7d8d284476af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-05-13T22:23:05.000Z - 2022-05-13T23:00:00.000Z: 238\n",
      "2022-05-13T23:00:00.000Z - 2022-05-14T00:00:00.000Z: 431\n",
      "2022-05-14T00:00:00.000Z - 2022-05-14T01:00:00.000Z: 327\n",
      "2022-05-14T01:00:00.000Z - 2022-05-14T02:00:00.000Z: 330\n",
      "2022-05-14T02:00:00.000Z - 2022-05-14T03:00:00.000Z: 452\n",
      "2022-05-14T03:00:00.000Z - 2022-05-14T04:00:00.000Z: 351\n",
      "2022-05-14T04:00:00.000Z - 2022-05-14T05:00:00.000Z: 286\n",
      "2022-05-14T05:00:00.000Z - 2022-05-14T06:00:00.000Z: 296\n",
      "2022-05-14T06:00:00.000Z - 2022-05-14T07:00:00.000Z: 227\n",
      "2022-05-14T07:00:00.000Z - 2022-05-14T08:00:00.000Z: 274\n",
      "2022-05-14T08:00:00.000Z - 2022-05-14T09:00:00.000Z: 237\n",
      "2022-05-14T09:00:00.000Z - 2022-05-14T10:00:00.000Z: 251\n",
      "2022-05-14T10:00:00.000Z - 2022-05-14T11:00:00.000Z: 301\n",
      "2022-05-14T11:00:00.000Z - 2022-05-14T12:00:00.000Z: 346\n",
      "2022-05-14T12:00:00.000Z - 2022-05-14T13:00:00.000Z: 453\n",
      "2022-05-14T13:00:00.000Z - 2022-05-14T14:00:00.000Z: 517\n",
      "2022-05-14T14:00:00.000Z - 2022-05-14T15:00:00.000Z: 474\n",
      "2022-05-14T15:00:00.000Z - 2022-05-14T16:00:00.000Z: 524\n",
      "2022-05-14T16:00:00.000Z - 2022-05-14T17:00:00.000Z: 677\n",
      "2022-05-14T17:00:00.000Z - 2022-05-14T18:00:00.000Z: 621\n",
      "2022-05-14T18:00:00.000Z - 2022-05-14T19:00:00.000Z: 833\n",
      "2022-05-14T19:00:00.000Z - 2022-05-14T20:00:00.000Z: 806\n",
      "2022-05-14T20:00:00.000Z - 2022-05-14T21:00:00.000Z: 570\n",
      "2022-05-14T21:00:00.000Z - 2022-05-14T22:00:00.000Z: 484\n",
      "2022-05-14T22:00:00.000Z - 2022-05-14T23:00:00.000Z: 602\n",
      "2022-05-14T23:00:00.000Z - 2022-05-15T00:00:00.000Z: 483\n",
      "2022-05-15T00:00:00.000Z - 2022-05-15T01:00:00.000Z: 505\n",
      "2022-05-15T01:00:00.000Z - 2022-05-15T02:00:00.000Z: 463\n",
      "2022-05-15T02:00:00.000Z - 2022-05-15T03:00:00.000Z: 464\n",
      "2022-05-15T03:00:00.000Z - 2022-05-15T04:00:00.000Z: 469\n",
      "2022-05-15T04:00:00.000Z - 2022-05-15T05:00:00.000Z: 574\n",
      "2022-05-15T05:00:00.000Z - 2022-05-15T06:00:00.000Z: 398\n",
      "2022-05-15T06:00:00.000Z - 2022-05-15T07:00:00.000Z: 428\n",
      "2022-05-15T07:00:00.000Z - 2022-05-15T08:00:00.000Z: 398\n",
      "2022-05-15T08:00:00.000Z - 2022-05-15T09:00:00.000Z: 356\n",
      "2022-05-15T09:00:00.000Z - 2022-05-15T10:00:00.000Z: 356\n",
      "2022-05-15T10:00:00.000Z - 2022-05-15T11:00:00.000Z: 354\n",
      "2022-05-15T11:00:00.000Z - 2022-05-15T12:00:00.000Z: 369\n",
      "2022-05-15T12:00:00.000Z - 2022-05-15T13:00:00.000Z: 418\n",
      "2022-05-15T13:00:00.000Z - 2022-05-15T14:00:00.000Z: 830\n",
      "2022-05-15T14:00:00.000Z - 2022-05-15T15:00:00.000Z: 1,645\n",
      "2022-05-15T15:00:00.000Z - 2022-05-15T16:00:00.000Z: 1,018\n",
      "2022-05-15T16:00:00.000Z - 2022-05-15T17:00:00.000Z: 908\n",
      "2022-05-15T17:00:00.000Z - 2022-05-15T18:00:00.000Z: 578\n",
      "2022-05-15T18:00:00.000Z - 2022-05-15T19:00:00.000Z: 556\n",
      "2022-05-15T19:00:00.000Z - 2022-05-15T20:00:00.000Z: 625\n",
      "2022-05-15T20:00:00.000Z - 2022-05-15T21:00:00.000Z: 535\n",
      "2022-05-15T21:00:00.000Z - 2022-05-15T22:00:00.000Z: 503\n",
      "2022-05-15T22:00:00.000Z - 2022-05-15T23:00:00.000Z: 435\n",
      "2022-05-15T23:00:00.000Z - 2022-05-16T00:00:00.000Z: 475\n",
      "2022-05-16T00:00:00.000Z - 2022-05-16T01:00:00.000Z: 413\n",
      "2022-05-16T01:00:00.000Z - 2022-05-16T02:00:00.000Z: 412\n",
      "2022-05-16T02:00:00.000Z - 2022-05-16T03:00:00.000Z: 356\n",
      "2022-05-16T03:00:00.000Z - 2022-05-16T04:00:00.000Z: 391\n",
      "2022-05-16T04:00:00.000Z - 2022-05-16T05:00:00.000Z: 359\n",
      "2022-05-16T05:00:00.000Z - 2022-05-16T06:00:00.000Z: 300\n",
      "2022-05-16T06:00:00.000Z - 2022-05-16T07:00:00.000Z: 361\n",
      "2022-05-16T07:00:00.000Z - 2022-05-16T08:00:00.000Z: 312\n",
      "2022-05-16T08:00:00.000Z - 2022-05-16T09:00:00.000Z: 253\n",
      "2022-05-16T09:00:00.000Z - 2022-05-16T10:00:00.000Z: 268\n",
      "2022-05-16T10:00:00.000Z - 2022-05-16T11:00:00.000Z: 282\n",
      "2022-05-16T11:00:00.000Z - 2022-05-16T12:00:00.000Z: 351\n",
      "2022-05-16T12:00:00.000Z - 2022-05-16T13:00:00.000Z: 380\n",
      "2022-05-16T13:00:00.000Z - 2022-05-16T14:00:00.000Z: 372\n",
      "2022-05-16T14:00:00.000Z - 2022-05-16T15:00:00.000Z: 377\n",
      "2022-05-16T15:00:00.000Z - 2022-05-16T16:00:00.000Z: 446\n",
      "2022-05-16T16:00:00.000Z - 2022-05-16T17:00:00.000Z: 591\n",
      "2022-05-16T17:00:00.000Z - 2022-05-16T18:00:00.000Z: 524\n",
      "2022-05-16T18:00:00.000Z - 2022-05-16T19:00:00.000Z: 437\n",
      "2022-05-16T19:00:00.000Z - 2022-05-16T20:00:00.000Z: 396\n",
      "2022-05-16T20:00:00.000Z - 2022-05-16T21:00:00.000Z: 367\n",
      "2022-05-16T21:00:00.000Z - 2022-05-16T22:00:00.000Z: 343\n",
      "2022-05-16T22:00:00.000Z - 2022-05-16T23:00:00.000Z: 472\n",
      "2022-05-16T23:00:00.000Z - 2022-05-17T00:00:00.000Z: 550\n",
      "2022-05-17T00:00:00.000Z - 2022-05-17T01:00:00.000Z: 326\n",
      "2022-05-17T01:00:00.000Z - 2022-05-17T02:00:00.000Z: 351\n",
      "2022-05-17T02:00:00.000Z - 2022-05-17T03:00:00.000Z: 306\n",
      "2022-05-17T03:00:00.000Z - 2022-05-17T04:00:00.000Z: 353\n",
      "2022-05-17T04:00:00.000Z - 2022-05-17T05:00:00.000Z: 312\n",
      "2022-05-17T05:00:00.000Z - 2022-05-17T06:00:00.000Z: 280\n",
      "2022-05-17T06:00:00.000Z - 2022-05-17T07:00:00.000Z: 228\n",
      "2022-05-17T07:00:00.000Z - 2022-05-17T08:00:00.000Z: 217\n",
      "2022-05-17T08:00:00.000Z - 2022-05-17T09:00:00.000Z: 268\n",
      "2022-05-17T09:00:00.000Z - 2022-05-17T10:00:00.000Z: 239\n",
      "2022-05-17T10:00:00.000Z - 2022-05-17T11:00:00.000Z: 248\n",
      "2022-05-17T11:00:00.000Z - 2022-05-17T12:00:00.000Z: 335\n",
      "2022-05-17T12:00:00.000Z - 2022-05-17T13:00:00.000Z: 327\n",
      "2022-05-17T13:00:00.000Z - 2022-05-17T14:00:00.000Z: 324\n",
      "2022-05-17T14:00:00.000Z - 2022-05-17T15:00:00.000Z: 384\n",
      "2022-05-17T15:00:00.000Z - 2022-05-17T16:00:00.000Z: 425\n",
      "2022-05-17T16:00:00.000Z - 2022-05-17T17:00:00.000Z: 429\n",
      "2022-05-17T17:00:00.000Z - 2022-05-17T18:00:00.000Z: 574\n",
      "2022-05-17T18:00:00.000Z - 2022-05-17T19:00:00.000Z: 444\n",
      "2022-05-17T19:00:00.000Z - 2022-05-17T20:00:00.000Z: 490\n",
      "2022-05-17T20:00:00.000Z - 2022-05-17T21:00:00.000Z: 461\n",
      "2022-05-17T21:00:00.000Z - 2022-05-17T22:00:00.000Z: 498\n",
      "2022-05-17T22:00:00.000Z - 2022-05-17T23:00:00.000Z: 550\n",
      "2022-05-17T23:00:00.000Z - 2022-05-18T00:00:00.000Z: 375\n",
      "2022-05-18T00:00:00.000Z - 2022-05-18T01:00:00.000Z: 417\n",
      "2022-05-18T01:00:00.000Z - 2022-05-18T02:00:00.000Z: 380\n",
      "2022-05-18T02:00:00.000Z - 2022-05-18T03:00:00.000Z: 413\n",
      "2022-05-18T03:00:00.000Z - 2022-05-18T04:00:00.000Z: 538\n",
      "2022-05-18T04:00:00.000Z - 2022-05-18T05:00:00.000Z: 343\n",
      "2022-05-18T05:00:00.000Z - 2022-05-18T06:00:00.000Z: 302\n",
      "2022-05-18T06:00:00.000Z - 2022-05-18T07:00:00.000Z: 287\n",
      "2022-05-18T07:00:00.000Z - 2022-05-18T08:00:00.000Z: 244\n",
      "2022-05-18T08:00:00.000Z - 2022-05-18T09:00:00.000Z: 268\n",
      "2022-05-18T09:00:00.000Z - 2022-05-18T10:00:00.000Z: 283\n",
      "2022-05-18T10:00:00.000Z - 2022-05-18T11:00:00.000Z: 264\n",
      "2022-05-18T11:00:00.000Z - 2022-05-18T12:00:00.000Z: 574\n",
      "2022-05-18T12:00:00.000Z - 2022-05-18T13:00:00.000Z: 467\n",
      "2022-05-18T13:00:00.000Z - 2022-05-18T14:00:00.000Z: 609\n",
      "2022-05-18T14:00:00.000Z - 2022-05-18T15:00:00.000Z: 452\n",
      "2022-05-18T15:00:00.000Z - 2022-05-18T16:00:00.000Z: 538\n",
      "2022-05-18T16:00:00.000Z - 2022-05-18T17:00:00.000Z: 553\n",
      "2022-05-18T17:00:00.000Z - 2022-05-18T18:00:00.000Z: 469\n",
      "2022-05-18T18:00:00.000Z - 2022-05-18T19:00:00.000Z: 386\n",
      "2022-05-18T19:00:00.000Z - 2022-05-18T20:00:00.000Z: 356\n",
      "2022-05-18T20:00:00.000Z - 2022-05-18T21:00:00.000Z: 328\n",
      "2022-05-18T21:00:00.000Z - 2022-05-18T22:00:00.000Z: 308\n",
      "2022-05-18T22:00:00.000Z - 2022-05-18T23:00:00.000Z: 444\n",
      "2022-05-18T23:00:00.000Z - 2022-05-19T00:00:00.000Z: 330\n",
      "2022-05-19T00:00:00.000Z - 2022-05-19T01:00:00.000Z: 473\n",
      "2022-05-19T01:00:00.000Z - 2022-05-19T02:00:00.000Z: 329\n",
      "2022-05-19T02:00:00.000Z - 2022-05-19T03:00:00.000Z: 396\n",
      "2022-05-19T03:00:00.000Z - 2022-05-19T04:00:00.000Z: 365\n",
      "2022-05-19T04:00:00.000Z - 2022-05-19T05:00:00.000Z: 384\n",
      "2022-05-19T05:00:00.000Z - 2022-05-19T06:00:00.000Z: 455\n",
      "2022-05-19T06:00:00.000Z - 2022-05-19T07:00:00.000Z: 362\n",
      "2022-05-19T07:00:00.000Z - 2022-05-19T08:00:00.000Z: 333\n",
      "2022-05-19T08:00:00.000Z - 2022-05-19T09:00:00.000Z: 284\n",
      "2022-05-19T09:00:00.000Z - 2022-05-19T10:00:00.000Z: 255\n",
      "2022-05-19T10:00:00.000Z - 2022-05-19T11:00:00.000Z: 309\n",
      "2022-05-19T11:00:00.000Z - 2022-05-19T12:00:00.000Z: 390\n",
      "2022-05-19T12:00:00.000Z - 2022-05-19T13:00:00.000Z: 379\n",
      "2022-05-19T13:00:00.000Z - 2022-05-19T14:00:00.000Z: 317\n",
      "2022-05-19T14:00:00.000Z - 2022-05-19T15:00:00.000Z: 392\n",
      "2022-05-19T15:00:00.000Z - 2022-05-19T16:00:00.000Z: 461\n",
      "2022-05-19T16:00:00.000Z - 2022-05-19T17:00:00.000Z: 428\n",
      "2022-05-19T17:00:00.000Z - 2022-05-19T18:00:00.000Z: 395\n",
      "2022-05-19T18:00:00.000Z - 2022-05-19T19:00:00.000Z: 433\n",
      "2022-05-19T19:00:00.000Z - 2022-05-19T20:00:00.000Z: 640\n",
      "2022-05-19T20:00:00.000Z - 2022-05-19T21:00:00.000Z: 527\n",
      "2022-05-19T21:00:00.000Z - 2022-05-19T22:00:00.000Z: 483\n",
      "2022-05-19T22:00:00.000Z - 2022-05-19T23:00:00.000Z: 552\n",
      "2022-05-19T23:00:00.000Z - 2022-05-20T00:00:00.000Z: 531\n",
      "2022-05-20T00:00:00.000Z - 2022-05-20T01:00:00.000Z: 512\n",
      "2022-05-20T01:00:00.000Z - 2022-05-20T02:00:00.000Z: 492\n",
      "2022-05-20T02:00:00.000Z - 2022-05-20T03:00:00.000Z: 578\n",
      "2022-05-20T03:00:00.000Z - 2022-05-20T04:00:00.000Z: 556\n",
      "2022-05-20T04:00:00.000Z - 2022-05-20T05:00:00.000Z: 504\n",
      "2022-05-20T05:00:00.000Z - 2022-05-20T06:00:00.000Z: 501\n",
      "2022-05-20T06:00:00.000Z - 2022-05-20T07:00:00.000Z: 415\n",
      "2022-05-20T07:00:00.000Z - 2022-05-20T08:00:00.000Z: 415\n",
      "2022-05-20T08:00:00.000Z - 2022-05-20T09:00:00.000Z: 379\n",
      "2022-05-20T09:00:00.000Z - 2022-05-20T10:00:00.000Z: 397\n",
      "2022-05-20T10:00:00.000Z - 2022-05-20T11:00:00.000Z: 375\n",
      "2022-05-20T11:00:00.000Z - 2022-05-20T12:00:00.000Z: 487\n",
      "2022-05-20T12:00:00.000Z - 2022-05-20T13:00:00.000Z: 452\n",
      "2022-05-20T13:00:00.000Z - 2022-05-20T14:00:00.000Z: 494\n",
      "2022-05-20T14:00:00.000Z - 2022-05-20T15:00:00.000Z: 422\n",
      "2022-05-20T15:00:00.000Z - 2022-05-20T16:00:00.000Z: 487\n",
      "2022-05-20T16:00:00.000Z - 2022-05-20T17:00:00.000Z: 663\n",
      "2022-05-20T17:00:00.000Z - 2022-05-20T18:00:00.000Z: 559\n",
      "2022-05-20T18:00:00.000Z - 2022-05-20T19:00:00.000Z: 440\n",
      "2022-05-20T19:00:00.000Z - 2022-05-20T20:00:00.000Z: 365\n",
      "2022-05-20T20:00:00.000Z - 2022-05-20T21:00:00.000Z: 447\n",
      "2022-05-20T21:00:00.000Z - 2022-05-20T22:00:00.000Z: 414\n",
      "2022-05-20T22:00:00.000Z - 2022-05-20T22:23:05.000Z: 223\n",
      "\u001b[32m\n",
      "Total Tweets: 73,111\n",
      "\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# fishing around for good searches\n",
    "# you can count without harvesting.\n",
    "# kittens is an evergreen search. you should always see at lease\n",
    "# dozens of mentions per hour\n",
    "!twarc2 counts --text \"kittens\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5795ab9-3a2c-4122-bf59-2bf002fa3d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# recent search with granularity.\n",
    "!twarc2 counts --granularity \"day\" --text \"(#UCSBLibrary OR UCSBLibrary OR ucsblibrary OR #ucsblibrary OR davidsonlibrary OR #davidsonlibrary)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e47ec3-1304-4a5f-9684-3266b1d0b621",
   "metadata": {},
   "outputs": [],
   "source": [
    "# phrase searching????\n",
    "# this one isnt working\n",
    "!twarc2 counts --granularity \"day\" --text \"(#UCSB OR UCSB OR ucsb OR (\"UC Santa Barbara\"))\"\n",
    "!twarc2 counts --granularity \"day\" --text \"(\"uc santa barbara\")\"\n",
    "!twarc2 counts --granularity \"day\" --text \"(#ucsb)\"\n",
    "!twarc2 counts --granularity \"day\" --text \"(UCSB)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "021f95fb-293d-459c-9afd-59d624efa865",
   "metadata": {},
   "outputs": [],
   "source": [
    "# search for hashtags when you really want hashtags. \n",
    "# search for a string returns both text and hashtage (an OR)\n",
    "# NOT case sensitive\n",
    "!twarc2 counts --granularity \"day\" --text \"(#UCSB OR UCSB OR ucsb)\"\n",
    "!twarc2 counts --granularity \"day\" --text \"(#ucsb)\"\n",
    "!twarc2 counts --granularity \"day\" --text \"(UCSB)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be3bd639-6118-4983-bb16-1ff7fd3999de",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Endpoints: counts\n",
    "!twarc2 counts --text \"(Poker OR poker)\" --granularity \"day\"\n",
    "!twarc2 counts --text \"(Golf OR golf)\" --granularity \"day\"\n",
    "!twarc2 counts --text \"(Basketball OR basketball)\" --granularity \"day\"\n",
    "!twarc2 counts --text \"(Baseball OR baseball)\" --granularity \"day\"\n",
    "!twarc2 counts --text \"(Football OR football)\" --granularity \"day\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5443c1c7-0da2-4ad9-82fd-1e9b2b377a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "## What's a lot?\n",
    "!twarc2 counts --text \"dog\" --granularity \"day\"\n",
    "!twarc2 counts --text \"cat\" --granularity \"day\"\n",
    "!twarc2 counts --text \"amazon\" --granularity \"day\"\n",
    "!twarc2 counts --text \"right\" --granularity \"day\"\n",
    "!twarc2 counts --text \"good\" --granularity \"day\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b64d9fa-d4d2-49c3-bf09-1e3a9d0ab35b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aab1b16f-69c8-4118-af77-dc38a99fc9a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ffc36b3-3fff-455a-b977-af257a34b5dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "abc52493-cf69-4298-8617-515a581ead59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████████| Processed 5.31M/5.31M of input file [00:00<00:00, 10.9MB/s]\n",
      "100%|██████████████| Processed 12.9M/12.9M of input file [00:02<00:00, 4.87MB/s]\n",
      "\n",
      "ℹ️\n",
      "Parsed 3226 tweets objects from 3226 lines in the input file.\n",
      "Wrote 3226 rows and output 74 columns in the CSV.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## a SFW timeline\n",
    "# !twarc2 timeline ucsblibrary raw_data/library.jsonl\n",
    "!twarc2 flatten raw_data/library.jsonl output_data/library.jsonl\n",
    "!twarc2 csv output_data/library.jsonl output_data/library.csv\n",
    "library_df = pandas.read_csv(\"output_data/library.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc06081-ef7c-4122-b7c0-0901ca4a2dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# confirm the dataframe's existance\n",
    "# and view all column headers\n",
    "list(library_df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5af9bd3-debf-4910-a2f1-30a760d599cd",
   "metadata": {},
   "source": [
    "### Converting to csv and dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44e2145d-a912-49ea-8044-544cb11bb38d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this line is not running\n",
    "# flatten it first?\n",
    "!twarc2 csv _data/taxday.jsonl output_data/taxday_flat.csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a492aa1b-dd0f-44f0-b0bc-dedec7d38b0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee4cc6aa-8a09-4b27-9dab-0b80cf267fcc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "23735a74-0dd1-4483-9705-595042b099bc",
   "metadata": {},
   "source": [
    "## final challenge: Cats of Instagram\n",
    "Let’s make a bigger datafile. Harvest 5000 tweets that use the hashtag “catsofinstagram” and put the dataset through the pipeline to answer the following questions:\n",
    "\n",
    "- Did you get exactly 5000?\n",
    "- How far back in time did you get?\n",
    "- What is the most re-tweeted recent tweet on #catsofinstagram?\n",
    "- Which person has the most number of followers in your dataset?\n",
    "- Is it really a person?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "952eed26-010f-464b-82c9-4699988555b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    5090  1075715 19340796 output_data/hashtagcats.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    2022-05-20T01:13:20.000Z\n",
       "1    2022-05-20T01:13:08.000Z\n",
       "2    2022-05-20T01:12:52.000Z\n",
       "3    2022-05-20T01:12:49.000Z\n",
       "4    2022-05-20T01:10:45.000Z\n",
       "Name: created_at, dtype: object"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# !twarc2 search --limit 5000 \"#catsofinstagram\" raw_data/hashtagcats.jsonl\n",
    "!twarc2 csv raw_data/hashtagcats.jsonl > output_data/hashtagcats.csv\n",
    "hashtagcats_df = pandas.read_csv(\"output_data/hashtagcats.csv\")\n",
    "! wc output_data/hashtagcats.csv\n",
    "hashtagcats_df[\"created_at\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac420468-385e-4d39-9f8c-d7e5f520c1be",
   "metadata": {},
   "outputs": [],
   "source": [
    "hashtagcats_df[\"created_at\"].tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f07c72-c097-4db9-8705-32e2b93c6aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "hashtagcats_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c151b25e-f551-445c-93ed-118406e3df40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['id',\n",
       " 'conversation_id',\n",
       " 'referenced_tweets.replied_to.id',\n",
       " 'referenced_tweets.retweeted.id',\n",
       " 'referenced_tweets.quoted.id',\n",
       " 'author_id',\n",
       " 'in_reply_to_user_id',\n",
       " 'retweeted_user_id',\n",
       " 'quoted_user_id',\n",
       " 'created_at',\n",
       " 'text',\n",
       " 'lang',\n",
       " 'source',\n",
       " 'public_metrics.like_count',\n",
       " 'public_metrics.quote_count',\n",
       " 'public_metrics.reply_count',\n",
       " 'public_metrics.retweet_count',\n",
       " 'reply_settings',\n",
       " 'possibly_sensitive',\n",
       " 'withheld.scope',\n",
       " 'withheld.copyright',\n",
       " 'withheld.country_codes',\n",
       " 'entities.annotations',\n",
       " 'entities.cashtags',\n",
       " 'entities.hashtags',\n",
       " 'entities.mentions',\n",
       " 'entities.urls',\n",
       " 'context_annotations',\n",
       " 'attachments.media',\n",
       " 'attachments.media_keys',\n",
       " 'attachments.poll.duration_minutes',\n",
       " 'attachments.poll.end_datetime',\n",
       " 'attachments.poll.id',\n",
       " 'attachments.poll.options',\n",
       " 'attachments.poll.voting_status',\n",
       " 'attachments.poll_ids',\n",
       " 'author.id',\n",
       " 'author.created_at',\n",
       " 'author.username',\n",
       " 'author.name',\n",
       " 'author.description',\n",
       " 'author.entities.description.cashtags',\n",
       " 'author.entities.description.hashtags',\n",
       " 'author.entities.description.mentions',\n",
       " 'author.entities.description.urls',\n",
       " 'author.entities.url.urls',\n",
       " 'author.location',\n",
       " 'author.pinned_tweet_id',\n",
       " 'author.profile_image_url',\n",
       " 'author.protected',\n",
       " 'author.public_metrics.followers_count',\n",
       " 'author.public_metrics.following_count',\n",
       " 'author.public_metrics.listed_count',\n",
       " 'author.public_metrics.tweet_count',\n",
       " 'author.url',\n",
       " 'author.verified',\n",
       " 'author.withheld.scope',\n",
       " 'author.withheld.copyright',\n",
       " 'author.withheld.country_codes',\n",
       " 'geo.coordinates.coordinates',\n",
       " 'geo.coordinates.type',\n",
       " 'geo.country',\n",
       " 'geo.country_code',\n",
       " 'geo.full_name',\n",
       " 'geo.geo.bbox',\n",
       " 'geo.geo.type',\n",
       " 'geo.id',\n",
       " 'geo.name',\n",
       " 'geo.place_id',\n",
       " 'geo.place_type',\n",
       " '__twarc.retrieved_at',\n",
       " '__twarc.url',\n",
       " '__twarc.version',\n",
       " 'Unnamed: 73']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(hashtagcats_df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "870d9fb7-03eb-4dcd-9ab8-d4888b008f65",
   "metadata": {},
   "source": [
    "# Episode 5: Ethics & Twitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f046b945-b698-4c9b-b6c4-8047382f16aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# our first full-text analysis\n",
    "# a list of words with TextBlob\n",
    "\n",
    "# first we need to munge the data. remember from:\n",
    "# list(library_df.columns)\n",
    "# the tweet is library_df['text']\n",
    "\n",
    "# TextBlob has its own data format.\n",
    "\n",
    "# break tweets test column into a list, \n",
    "# then .join into one long string \n",
    "library_string = ' '.join(library_df['text'].tolist())\n",
    "# turn the string into a blob\n",
    "library_blob = textblob.TextBlob(library_string)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4522956e-9332-4219-a21b-7e2dfbf3bc02",
   "metadata": {},
   "source": [
    "This produces a mess. \n",
    "Let's count the words and sort by their frequency of use:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1a5a3b36-fffd-477c-91bb-cdf315dbe285",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('https', 2282),\n",
       " ('to', 1646),\n",
       " ('of', 1523),\n",
       " ('and', 1244),\n",
       " ('ucsb', 1148),\n",
       " ('http', 1117),\n",
       " ('in', 1107),\n",
       " ('library', 1071),\n",
       " ('a', 1047),\n",
       " ('for', 1012),\n",
       " ('s', 745),\n",
       " ('on', 671),\n",
       " ('at', 634),\n",
       " ('you', 605),\n",
       " ('our', 547),\n",
       " ('we', 532),\n",
       " ('is', 499),\n",
       " ('from', 475),\n",
       " ('this', 453),\n",
       " ('ucsblibrary', 415),\n",
       " ('with', 391),\n",
       " ('by', 391),\n",
       " ('amp', 331),\n",
       " ('more', 327)]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "library_freq = library_blob.word_counts\n",
    "library_sorted_freq = sorted(library_freq.items(), \n",
    "                             key = lambda kv: kv[1], \n",
    "                             reverse = True)\n",
    "library_sorted_freq[1:25]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfa676be-7ceb-45e8-82e8-7429b8884d7b",
   "metadata": {},
   "source": [
    "We can at least get the english stopwords out. but this all didn't reall produce anything cleaner:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b5cd1c12-d78a-44e5-9376-26b4a0589785",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the stopwords to use\n",
    "from nltk.corpus import stopwords\n",
    "sw_nltk = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e878e6b7-2c29-45e8-83cd-fb0eefd3b668",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new text list that does\n",
    "# NOT contain stopwords\n",
    "library_str_stopped = [word for word in library_string.split() \n",
    "                       if word.lower() not in sw_nltk]\n",
    "library_words_stopped = \" \".join(library_str_stopped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6e27a5b1-0519-407c-ae52-abd0587857a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ucsb', 1148),\n",
       " ('http', 1117),\n",
       " ('library', 1071),\n",
       " ('s', 679),\n",
       " ('ucsblibrary', 415),\n",
       " ('amp', 331),\n",
       " ('new', 288),\n",
       " ('today', 250),\n",
       " ('us', 232),\n",
       " ('’', 228),\n",
       " ('book', 218),\n",
       " ('research', 212),\n",
       " ('here', 210),\n",
       " ('students', 195),\n",
       " ('reads', 189),\n",
       " ('open', 187),\n",
       " ('we', 178),\n",
       " ('check', 177),\n",
       " ('join', 164),\n",
       " ('week', 161),\n",
       " ('floor', 145),\n",
       " ('day', 143),\n",
       " ('free', 139),\n",
       " ('collections', 138),\n",
       " ('access', 136),\n",
       " ('art', 127),\n",
       " ('re', 126),\n",
       " ('special', 120),\n",
       " ('study', 119),\n",
       " ('learn', 116),\n",
       " ('collection', 112),\n",
       " ('first', 108),\n",
       " ('campus', 106),\n",
       " ('one', 103),\n",
       " ('info', 102),\n",
       " ('books', 102),\n",
       " ('available', 102),\n",
       " ('see', 100),\n",
       " ('uc', 99),\n",
       " ('come', 99),\n",
       " ('librarian', 98),\n",
       " ('community', 97),\n",
       " ('student', 97),\n",
       " ('talk', 96),\n",
       " ('exhibit', 95),\n",
       " ('hours', 93),\n",
       " ('more', 92),\n",
       " ('read', 90),\n",
       " ('science', 89)]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "library_blob_stopped = textblob.TextBlob(library_words_stopped)\n",
    "library_blob_stopped_freq = library_blob_stopped.word_counts\n",
    "library_blob_stopped_sorted_freq = sorted(library_blob_stopped_freq.items(), \n",
    "                             key = lambda kv: kv[1], \n",
    "                             reverse = True)\n",
    "library_blob_stopped_sorted_freq[1:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e7e02e4b-e055-47a8-a99a-03e47a9868c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('new', 288),\n",
       " ('today', 250),\n",
       " ('us', 232),\n",
       " ('’', 228),\n",
       " ('book', 218),\n",
       " ('research', 212),\n",
       " ('here', 210),\n",
       " ('students', 195),\n",
       " ('reads', 189),\n",
       " ('open', 187),\n",
       " ('we', 178),\n",
       " ('check', 177),\n",
       " ('join', 164),\n",
       " ('week', 161),\n",
       " ('floor', 145),\n",
       " ('day', 143),\n",
       " ('free', 139),\n",
       " ('collections', 138),\n",
       " ('access', 136),\n",
       " ('art', 127),\n",
       " ('re', 126),\n",
       " ('special', 120),\n",
       " ('study', 119),\n",
       " ('learn', 116),\n",
       " ('collection', 112),\n",
       " ('first', 108),\n",
       " ('campus', 106),\n",
       " ('one', 103),\n",
       " ('info', 102),\n",
       " ('books', 102),\n",
       " ('available', 102),\n",
       " ('see', 100),\n",
       " ('uc', 99),\n",
       " ('come', 99),\n",
       " ('librarian', 98),\n",
       " ('community', 97),\n",
       " ('student', 97),\n",
       " ('talk', 96),\n",
       " ('exhibit', 95),\n",
       " ('hours', 93),\n",
       " ('more', 92),\n",
       " ('read', 90),\n",
       " ('science', 89),\n",
       " ('“', 87),\n",
       " ('”', 86),\n",
       " ('time', 86),\n",
       " ('barbara', 85),\n",
       " ('tbt', 84),\n",
       " ('santa', 83),\n",
       " ('year', 82)]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a more meaningul segment\n",
    "library_blob_stopped_sorted_freq[7:57]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c343fbf8-241c-4ec7-8b6e-da4c3db73717",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(library_stopped_blob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e074d32e-4a94-4add-89b3-cf0863340cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Challenge: for the Python wizzes. #FIXME\n",
    "# do that in a tidy way?\n",
    "# what do pandas pipes look like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "fc855355-2742-47b4-a166-194898ded55b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/jovyan/twarc_run/utils/wall.py\", line 147, in <module>\n",
      "    url = tweet[\"user\"][\"profile_image_url\"]\n",
      "KeyError: 'user'\n"
     ]
    }
   ],
   "source": [
    "# we made the utils folder during setup\n",
    "# https://github.com/DocNow/twarc/tree/main/utils\n",
    "\n",
    "!python utils/wall.py raw_data/hashtagcats.jsonl > output_data/hashtagcats.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f05c175a-1049-49b8-a4ad-672249bceb28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# you gotta flatten that shit\n",
    "!twarc2 flatten raw_data/hashtagcats.jsonl > output_data/hashtagcats_flat.jsonl\n",
    "# !python utils/wall.py output_data/hashtagcats_flat.jsonl > output_data/hashtagcats.html\n",
    "\n",
    "# or maybe not flatten.\n",
    "# either way, I can't get it to run\n",
    "! python utils/wall.py raw_data/hashtagcats.jsonl > output_data/cat_wall.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bc9aad4-1981-4911-ac2e-18bb3b0e92ae",
   "metadata": {},
   "source": [
    "## Challenge: Insta-rrectionists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe5551d5-4b64-4731-9285-82bfc5fd9a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this takes a very long time.\n",
    "# !twarc2 hydrate raw_data/dehydratedCapitolRiotTweets.txt output_data/riots.jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76119af0-f58e-4bb4-a296-f0718b28a05b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# how long is this?\n",
    "riots_dehydrated_df = pandas.read_csv(\"raw_data/dehydratedCapitolRiotTweets.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae63a6f5-71af-4a07-a940-d96b45ebd1a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "12ca8fc4-ac95-4535-8146-843e2126e915",
   "metadata": {},
   "source": [
    "# Episode 6: Working with our Tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e70e7058-cdc6-4b96-98ef-03d261c3b051",
   "metadata": {},
   "source": [
    "1. retweets\n",
    "1. emojis\n",
    "1. wall\n",
    "1. followers\n",
    "1. retweeted-by"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76d86256-2a22-4031-9a3d-d76b0ba3f3e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# what does this do?\n",
    "# it shows the tweet ID's of the Retweets in your dataset, and how much\n",
    "!python utils/retweets.py raw_data/taxday.jsonl > output_data/taxday_retweets.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe5339c7-2114-43e9-8cad-49a0c714fd8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we gotta make sure that works with newly harvested stuff\n",
    "!python utils/retweets.py raw_data/ucsblibrary_mentions.jsonl > output_data/ucsblibrary_mentions.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1613374d-4e09-4914-8ab8-eb967b70b9cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5281953c-f01a-4d24-ad9e-239aa71470bc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!python utils/emojis.py raw_data/taxday.jsonl > output_data/taxday_emojis.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "187e274c-6481-4f37-8ee5-29806da7be7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! twarc2 mentions ucsblibrary raw_data/ucsblibrary_mentions.jsonl\n",
    "! twarc2 csv raw_data/ucsblibrary_mentions.jsonl output_data/ucsblibrary_mentions.csv \n",
    "ucsb_library_mentions_df = pandas.read_csv('output_data/ucsblibrary_mentions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c897bf85-dfc0-4557-af4e-0e662eaa92da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# emojis for each of our datasets so far\n",
    "# !python utils/emojis.py raw_data/hashtagcats.jsonl > output_data/hashtagcats_emojis.csv\n",
    "!python utils/emojis.py raw_data/ucsblibrary_mentions.jsonl > output_data/ucsblibrary_mentions_emojis.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4388d91c-dcfe-4fc3-b215-ff0c2a1c0dda",
   "metadata": {},
   "source": [
    "# Retweets vs. tweets\n",
    "How much original content is there?\n",
    "Do this for both taxday, library, and one of the cats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2442d03-bfc2-4a75-bc8d-3386b30bfe15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with the util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a066d059-1867-449e-8230-72faa359c6e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d6e8c9-2d81-4868-923b-ca5b4c10815e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c965f46-311a-4add-97a0-403a647ee7d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceb74589-f708-4ab5-9a2b-00c2478d4020",
   "metadata": {},
   "outputs": [],
   "source": [
    "# via pandas and plottting\n",
    "tax_retweets_df = pandas.read_csv(\"output_data/taxday_retweets.csv\", names=[\"tweetid\", \"retweets\"])\n",
    "tax_retweets_df.head()\n",
    "tax_retweets_df[\"retweets\"].plot(kind = \"hist\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "371d1385-a265-4e0b-a36f-064a9b5ac444",
   "metadata": {},
   "outputs": [],
   "source": [
    "retweet_total = sum(tax_retweets_df[\"retweets\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a974343-f4c3-4e3c-99c7-67d975cea76b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tax_retweets_df[\"retweets\"].plot(kind = \"hist\", loglog=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b45c780-7130-4cd3-be66-13d634bb50c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# new beginning\n",
    "# can I get a fresh filter and run emojis?\n",
    "! twarc2 search \"masked OR #masked\" raw_data/masked.jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa0cb88-7b79-4cb5-a33d-e525857e3d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "! twarc2 flatten raw_data/masked.jsonl output_data/masked_flat.jsonl "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "236d4801-562a-45f0-ada7-b16560a189f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python utils/emojis.py output_data/masked_flat.jsonl > output_data/masked_emojis.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d6da4f1-7a9a-47ef-a5ce-d4e5a3920752",
   "metadata": {},
   "source": [
    "# Episode 7: Search and Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afb13818-26a5-4d6a-bcf1-f99b3d7c966c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use Twitter advanced search syntax (everthing in quotes!)\n",
    "# to get tailored results\n",
    "!twarc2 search --limit 800 \"(cute OR fluffy OR haircut) (#catsofinstagram) lang:en\" kittens.jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec3cfcd-55cb-4434-b633-b548cb321141",
   "metadata": {},
   "outputs": [],
   "source": [
    "kittens_df = pandas.read_csv(\"output_data/kittens.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c8aa01-430a-4599-a65d-aaac822ff8c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "kittens_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0015b8ec-3e79-46d8-8f76-9aa7c5dc66b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(kittens_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a264ec5-4174-4e62-a3cd-9e16aef94059",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e9ff6e98-1dc9-43c6-be95-ecf88045147a",
   "metadata": {},
   "source": [
    "# Episode 8: Python text analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ccc6de7-126c-4975-8f1e-cacd1140ff34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# what datafram is still here?\n",
    "hashtagcats_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6c3b41d-cfc2-4a41-b710-4145d2fbb0af",
   "metadata": {},
   "source": [
    "### Sentiment Analysis\n",
    "To do this, we need to do a little Python\n",
    "\n",
    "TextBlob is a text processing library that does sentiment analysis. \n",
    "The sentiment property returns a namedtuple of the form Sentiment(polarity, subjectivity). The polarity score is a float within the range [-1.0, 1.0]. The subjectivity is a float within the range [0.0, 1.0] where 0.0 is very objective and 1.0 is very subjective."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd4d69fd-adcc-46a6-9a46-83cb991e52b9",
   "metadata": {},
   "source": [
    "Before we use TextBlob for sentiment analysis, we need to download\n",
    "datasets of words and their associated weights. These are called *corpora*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "423c7d9b-b67d-4b13-8894-75a64654b52d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# commented out because I put it up in ep 2\n",
    "# !python -m textblob.download_corpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c5bbf73-444b-41a2-a72c-deb388217096",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TextBlob needs a string, so this won't work.\n",
    "textblob.TextBlob(hashtagcats_df).sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2c21bf8-b1ec-4405-94bc-b77c599e4b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# even calling the column won't work:\n",
    "textblob.TextBlob(hashtagcats_df['text']).sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6874ca27-b81f-4f4f-911b-68e9fe21384e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# break tweets test column into a list, then .join into one long string \n",
    "hashtagcats_list = ' '.join(hashtagcats_df['text'].tolist())\n",
    "# turn the string into a blob\n",
    "hashtagcats_blob = textblob.TextBlob(hashtagcats_list)\n",
    "# get the sentiment\n",
    "hashtagcats_blob.sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "005ba8f5-5054-4fba-8e12-0bade66f4775",
   "metadata": {
    "tags": []
   },
   "source": [
    "The overall sentiment of the language of kitty twitter is rather positive.\n",
    "And the tweets tend to be subjective."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f7f70c-b9ee-45cf-ad37-7a26cc43d559",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What do you think the sentiment of tax day might be?\n",
    "# get the overall sentiment and see if it matches your prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9856bda0-b290-40a0-ad22-32ece206312b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f0e6acd1-e68a-4b01-873b-a3aaebd440fd",
   "metadata": {},
   "source": [
    "# Episode 9: Data Management"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12ad30b5-e686-4487-8430-65fc3ab1b993",
   "metadata": {},
   "source": [
    "# Episode 10: Don't Map Twitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d4e4d3d-71a6-4fe7-8b30-542ea123b4ad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
