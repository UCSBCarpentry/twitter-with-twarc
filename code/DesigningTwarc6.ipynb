{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "744056f4-ef73-4c90-a7bc-aef8167fd1cc",
   "metadata": {},
   "source": [
    "# Twitter with twarc\n",
    "A UCSB Carpentry workshop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1324c4e6-ab87-441e-bd4e-860eec5ccfe8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "35e9818e-0cc6-474e-b92b-28467ca18d4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: twarc-csv in /opt/conda/lib/python3.9/site-packages (0.5.2)\n",
      "Requirement already satisfied: more-itertools>=8.7.0 in /opt/conda/lib/python3.9/site-packages (from twarc-csv) (8.13.0)\n",
      "Requirement already satisfied: tqdm>=4.59.0 in /opt/conda/lib/python3.9/site-packages (from twarc-csv) (4.64.0)\n",
      "Requirement already satisfied: pandas>=1.2.5 in /opt/conda/lib/python3.9/site-packages (from twarc-csv) (1.4.2)\n",
      "Requirement already satisfied: twarc>=2.9.5 in /opt/conda/lib/python3.9/site-packages (from twarc-csv) (2.10.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /opt/conda/lib/python3.9/site-packages (from pandas>=1.2.5->twarc-csv) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.9/site-packages (from pandas>=1.2.5->twarc-csv) (2022.1)\n",
      "Requirement already satisfied: numpy>=1.18.5 in /opt/conda/lib/python3.9/site-packages (from pandas>=1.2.5->twarc-csv) (1.22.3)\n",
      "Requirement already satisfied: click<9,>=7 in /opt/conda/lib/python3.9/site-packages (from twarc>=2.9.5->twarc-csv) (8.1.3)\n",
      "Requirement already satisfied: requests-oauthlib>=1.3 in /opt/conda/lib/python3.9/site-packages (from twarc>=2.9.5->twarc-csv) (1.3.1)\n",
      "Requirement already satisfied: click-plugins>=1 in /opt/conda/lib/python3.9/site-packages (from twarc>=2.9.5->twarc-csv) (1.1.1)\n",
      "Requirement already satisfied: humanize>=3.9 in /opt/conda/lib/python3.9/site-packages (from twarc>=2.9.5->twarc-csv) (4.1.0)\n",
      "Requirement already satisfied: click-config-file>=0.6 in /opt/conda/lib/python3.9/site-packages (from twarc>=2.9.5->twarc-csv) (0.6.0)\n",
      "Requirement already satisfied: configobj>=5.0.6 in /opt/conda/lib/python3.9/site-packages (from click-config-file>=0.6->twarc>=2.9.5->twarc-csv) (5.0.6)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.9/site-packages (from python-dateutil>=2.8.1->pandas>=1.2.5->twarc-csv) (1.16.0)\n",
      "Requirement already satisfied: requests>=2.0.0 in /opt/conda/lib/python3.9/site-packages (from requests-oauthlib>=1.3->twarc>=2.9.5->twarc-csv) (2.27.1)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.9/site-packages (from requests-oauthlib>=1.3->twarc>=2.9.5->twarc-csv) (3.2.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.9/site-packages (from requests>=2.0.0->requests-oauthlib>=1.3->twarc>=2.9.5->twarc-csv) (1.26.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.9/site-packages (from requests>=2.0.0->requests-oauthlib>=1.3->twarc>=2.9.5->twarc-csv) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.9/site-packages (from requests>=2.0.0->requests-oauthlib>=1.3->twarc>=2.9.5->twarc-csv) (2.0.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.9/site-packages (from requests>=2.0.0->requests-oauthlib>=1.3->twarc>=2.9.5->twarc-csv) (3.3)\n",
      "Requirement already satisfied: emoji in /opt/conda/lib/python3.9/site-packages (1.7.0)\n"
     ]
    }
   ],
   "source": [
    "# administravia\n",
    "# upon re-start we need to install twarc2 extensions\n",
    "! pip install twarc-csv\n",
    "! pip install emoji\n",
    "\n",
    "\n",
    "# nltk.download('stopwords')\n",
    "#this one throws an error. it needs to come later."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2b8339f-952b-498f-bc0f-a5eda41a38e0",
   "metadata": {},
   "source": [
    "# Episode 2\n",
    "You should have a taxday.jsonl file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3cbf7282-bf3d-4a51-ad72-008ccaef1a13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usage: twarc2 [OPTIONS] COMMAND [ARGS]...\n",
      "\n",
      "  Collect data from the Twitter V2 API.\n",
      "\n",
      "Options:\n",
      "  --consumer-key TEXT         Twitter app consumer key (aka \"App Key\")\n",
      "  --consumer-secret TEXT      Twitter app consumer secret (aka \"App Secret\")\n",
      "  --access-token TEXT         Twitter app access token for user\n",
      "                              authentication.\n",
      "  --access-token-secret TEXT  Twitter app access token secret for user\n",
      "                              authentication.\n",
      "  --bearer-token TEXT         Twitter app access bearer token.\n",
      "  --app-auth / --user-auth    Use application authentication or user\n",
      "                              authentication. Some rate limits are higher with\n",
      "                              user authentication, but not all endpoints are\n",
      "                              supported.  [default: app-auth]\n",
      "  -l, --log TEXT\n",
      "  --verbose\n",
      "  --metadata / --no-metadata  Include/don't include metadata about when and\n",
      "                              how data was collected.  [default: metadata]\n",
      "  --config FILE               Read configuration from FILE.\n",
      "  --help                      Show this message and exit.\n",
      "\n",
      "Commands:\n",
      "  compliance-job  Create, retrieve and list batch compliance jobs for...\n",
      "  configure       Set up your Twitter app keys.\n",
      "  conversation    Retrieve a conversation thread using the tweet id.\n",
      "  conversations   Fetch the full conversation threads that the input...\n",
      "  counts          Return counts of tweets matching a query.\n",
      "  csv             Convert tweets to CSV.\n",
      "  dehydrate       Extract tweet or user IDs from a dataset.\n",
      "  flatten         \"Flatten\" tweets, or move expansions inline with tweet...\n",
      "  followers       Get the followers for a given user.\n",
      "  following       Get the users that a given user is following.\n",
      "  hydrate         Hydrate tweet ids.\n",
      "  liked-tweets    Get the tweets liked by a specific user_id.\n",
      "  liking-users    Get the users that liked a specific tweet.\n",
      "  lists           Lists API support.\n",
      "  mentions        Retrieve max of 800 of the most recent tweets...\n",
      "  places          Search for places by place name, geo coordinates or ip...\n",
      "  quotes          Get the tweets that quote tweet the given tweet.\n",
      "  retweeted-by    Get the users that retweeted a specific tweet.\n",
      "  sample          Fetch tweets from the sample stream.\n",
      "  search          Search for tweets.\n",
      "  searches        Execute each search in the input file, one at a time.\n",
      "  stream          Fetch tweets from the live stream.\n",
      "  stream-rules    List, add and delete rules for your stream.\n",
      "  timeline        Retrieve recent tweets for the given user.\n",
      "  timelines       Fetch the timelines of every user in an input source of...\n",
      "  tweet           Look up a tweet using its tweet id or URL.\n",
      "  user            Get the profile data for a single user by either...\n",
      "  users           Get data for user ids or usernames.\n",
      "  version         Return the version of twarc that is installed.\n"
     ]
    }
   ],
   "source": [
    "# BASH commands start with a BANG!\n",
    "!twarc2 --help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d2ad701f-463e-40f9-958b-a09721e263d4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#  what libraries will we need to be loading in our notebook?\n",
    "#  we need to always distinguish between \n",
    "#  running BASH vs. running a line of python.\n",
    "\n",
    "import pandas\n",
    "import twarc_csv\n",
    "import textblob\n",
    "import nltk\n",
    "import os\n",
    "import emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "2082bb24-2751-406c-a918-c8c41d14e7b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jovyan/twarc_run\n"
     ]
    }
   ],
   "source": [
    "# and of course, it's important to know where we are working\n",
    "# I can send a BASH command from my notebook with a !:\n",
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8098e978-172e-4949-a531-1a05fa43be25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/jovyan/twarc_run'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# you can also do this with Python\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc19b894-b858-4966-ae5e-e32bff6bde2e",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'twarc_run'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# make sure we are in the twarc_run folder\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchdir\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtwarc_run\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'twarc_run'"
     ]
    }
   ],
   "source": [
    "# make sure we are in the twarc_run folder\n",
    "os.chdir(\"twarc_run\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "17a6e89d-7e91-4558-ae3f-aa1026554cef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/jovyan/twarc_run'"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5913eea7-a65c-4505-b1c5-a846d7a98d23",
   "metadata": {},
   "source": [
    "## Running twarc\n",
    "Let's get the timeline of one of twarc's creators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "222e98bb-b6fa-442e-b1e9-5f5b72e518e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!twarc2 timeline BergisJules > raw_data/bjules.jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eaf04f84-943a-4d7b-a45e-d007e6b5abc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████████| Processed 8.95M/8.95M of input file [00:00<00:00, 10.7MB/s]\n"
     ]
    }
   ],
   "source": [
    "# timeline objects need to be flattened in order to be analyzed as tweets\n",
    "!twarc2 flatten raw_data/bjules.jsonl output_data/bjules_flat.jsonl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4473db7c-3651-45f7-8c14-0f49b6c5c0f4",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Challenge 1\n",
    "- Can you find the file called “bjules_flat.jsonl”?\n",
    "- What's the timestamp on the first one. The last one?\n",
    "\n",
    "- How many tweets did you get from Bergis? (we can't tell without flattening)\n",
    "- Download a timeline for a person of your choice. How many tweets did you get? \n",
    "- What’s the oldest one?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bab10779-cc96-4ed0-9e47-2e8faac15d93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    473  204893 2875654 output_data/ecodatasci_flat.jsonl\n"
     ]
    }
   ],
   "source": [
    "!twarc2 flatten raw_data/ecodatasci.jsonl > output_data/ecodatasci_flat.jsonl\n",
    "!wc output_data/ecodatasci_flat.jsonl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08892a04-a2be-4353-b64c-43a628e5ae50",
   "metadata": {},
   "source": [
    "## Convert to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1b29144d-a627-4128-b54f-74439f37a917",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████████| Processed 8.95M/8.95M of input file [00:02<00:00, 3.60MB/s]\n",
      "\n",
      "ℹ️\n",
      "Parsed 3140 tweets objects from 33 lines in the input file.\n",
      "Wrote 3140 rows and output 74 columns in the CSV.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!twarc2 csv raw_data/bjules.jsonl output_data/bjules.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2316f7fe-1614-404c-9516-897fd6415a7b",
   "metadata": {},
   "source": [
    "### Challenge 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1284486c-4487-401d-b421-20c4597dfedd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# commented line is a solution to challenge 1\n",
    "# !twarc2 timeline ecodatasci > raw_data/ecodatasci.jsonl\n",
    "\n",
    "!twarc2 csv output_data/ecodatasci_flat.jsonl > output_data/ecodatasci.csv \n",
    "ecodatasci_df = pandas.read_csv(\"output_data/ecodatasci.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7aecabff-dbda-4c8c-addc-a7132c3df302",
   "metadata": {},
   "outputs": [],
   "source": [
    "!twarc2 flatten raw_data/ecodatasci.jsonl > output_data/ecodatasci_flat.jsonl\n",
    "!twarc2 csv output_data/ecodatasci_flat.jsonl > output_data/ecodatasci.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f31b31-3360-4d6f-84b4-0db227a1a335",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bbfccda8-2a25-44a3-bb9a-5bdbc2c6d6cb",
   "metadata": {},
   "source": [
    "# Episode 3: examining tweets\n",
    "What comes along with a tweet\n",
    "- Look at one_tweet in Jupyter viewer\n",
    "- Look at one_tweet with nano\n",
    "- Look at tweet as csv\n",
    "- Look at all the entities of a tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba9ab04-d27d-42bd-9a60-9f3a7198cff8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dbcb8c10-7fe2-4d91-bc0a-7267ec5062cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|████████████████| Processed 299k/299k of input file [00:00<00:00, 6.48MB/s]\n",
      "\n",
      "ℹ️\n",
      "Parsed 0 tweets objects from 35 lines in the input file.\n",
      "\u001b[31m34 failed to parse. See twarc.log for details.\n",
      "\u001b[0mWrote 0 rows and output 74 columns in the CSV.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### Let's look at a tweet as a csv:\n",
    "!twarc2 csv raw_data/one_tweet.jsonl output_data/one_tweet.csv\n",
    "# this isn't running"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99766d53-53ea-4ef2-b201-2e58c89d411d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## To flatten or not flatten"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "586f4cbf-4741-44e2-a025-9968faf74e77",
   "metadata": {},
   "source": [
    "### Make your jsonl 1 tweet per line\n",
    "This will let you do our most basic unix-y analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7b7bd894-4995-4851-8668-983c3c4c9f35",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    15698   7653538 100048736 raw_data/taxday.jsonl\n"
     ]
    }
   ],
   "source": [
    "!wc raw_data/taxday.jsonl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bbe2b98-3264-45bc-adc0-f6aa567718cd",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Try again\n",
    "33 lines doesn't mean 33 tweets. I suspected there was more there becauce\n",
    "I got an error message about hitting a limit of 3200. \n",
    "\n",
    "We need to either flatten our tweets, or convert them\n",
    "to a csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b1dc091e-8fb8-49ab-b6d5-58e454d4bc90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████████| Processed 95.4M/95.4M of input file [00:04<00:00, 24.5MB/s]\n"
     ]
    }
   ],
   "source": [
    "# flatten\n",
    "!twarc2 flatten raw_data/taxday.jsonl output_data/taxday_flat.jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cd5bd6d9-24f4-4a93-9222-1dad58059328",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    15698   7653538 100048736 output_data/taxday_flat.jsonl\n"
     ]
    }
   ],
   "source": [
    "!wc output_data/taxday_flat.jsonl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a8c4d85-fa2a-4e7d-9e7c-1fa1207d64fc",
   "metadata": {},
   "source": [
    "## When we look at bjules, we really do need to flatten it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c9015236-250a-4f85-83b0-296431fe65a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████████| Processed 8.95M/8.95M of input file [00:02<00:00, 3.71MB/s]\n",
      "\n",
      "ℹ️\n",
      "Parsed 3140 tweets objects from 33 lines in the input file.\n",
      "Wrote 3140 rows and output 74 columns in the CSV.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# convert\n",
    "!twarc2 csv raw_data/bjules.jsonl output_data/bjules.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "180e3158-2f08-4d08-8e9e-b4ab999e6ef1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wc: output_data/bjules_flattened.jsonl: No such file or directory\n",
      "    3141   578566 11534972 output_data/bjules.csv\n"
     ]
    }
   ],
   "source": [
    "# When I did this, I got 3166 tweets (as opposed to the 33 lines that the original file was)\n",
    "! wc output_data/bjules_flattened.jsonl\n",
    "! wc output_data/bjules.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d55e1a66-f173-4adb-898c-572f15c7bbcb",
   "metadata": {},
   "source": [
    "The csv is 1 line longer because it has column headers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab4c78d8-42bd-458c-b618-d1c854fc265f",
   "metadata": {},
   "source": [
    "Can we go back further on his timeline by looking\n",
    "only for Bergis's original content?\n",
    "\n",
    "No--the same limit applies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b29e6727-48e8-4c79-b824-fd109b0e7029",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API limit of 3200 reached:   0%|             | 47/17680 [00:00<03:54, 75.05it/s]\n"
     ]
    }
   ],
   "source": [
    "!twarc2 timeline BergisJules --exclude-retweets --exclude-replies > raw_data/bjules_original"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ec876b9-c5b4-463a-8552-af4c0b97c446",
   "metadata": {},
   "source": [
    "Let's look at out taxday.jsonl file that we prepared for you on April 18."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c876b6-789d-408f-b164-bdd1f6aaddcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "!head -n 1 raw_data/taxday.jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f64d26-ae10-4deb-bf48-47f88b7db62f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d6efcdaf-a547-4a93-95d3-94e4bfcdddff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usage: twarc2 flatten [OPTIONS] [INFILE] [OUTFILE]\n",
      "Try 'twarc2 flatten --help' for help.\n",
      "\n",
      "Error: Invalid value for '[INFILE]': 'raw_data/bjules_original.jsonl': No such file or directory\n"
     ]
    }
   ],
   "source": [
    "!twarc2 flatten raw_data/bjules_original.jsonl output_data/bjules_original_flat.jsonl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a685310-f080-4ff8-8728-a46ca21f926b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e4a5ce0-373b-4106-8959-31850ae8fb17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A lot comes along! \n",
    "!tail -n 1 raw_data/taxday.jsonl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e89e3a4e-4955-426a-9081-1ea9739304c9",
   "metadata": {},
   "source": [
    "## Challenge: tax day Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "67d95d44-829c-431c-bd6c-7ee4b842506a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    15698   7653538 100048736 raw_data/taxday.jsonl\n",
      "    15698   7653538 100048736 output_data/taxday_flat.jsonl\n"
     ]
    }
   ],
   "source": [
    "# we harvested 3 hours worth of tweets for you on tax day.\n",
    "# how many tweets?\n",
    "!wc raw_data/taxday.jsonl\n",
    "!wc output_data/taxday_flat.jsonl\n",
    "# same number, so we don't have to flatten these."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af2f2152-7de1-40d4-9d97-c6aa551ce2fd",
   "metadata": {},
   "source": [
    "## Next harvest\n",
    "Next we'll get just Bergis' original content. \n",
    "In other words, only the tweets that he wrote, not\n",
    "any retweets or replied to other people tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb6ab7f-2bb4-47d0-bfa8-acb7e9ad77ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e67c2f11-27b4-4802-9d94-19589291e94d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3310f048-6ad7-4ee6-bd4e-c727ec8031a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd90d6c-c9b9-41e5-ae9d-6b3c457cbc9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# maybe the last challenge for ep. 3 is examining this shorter file?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29ab11e8-f109-4670-912c-3122ea2b8211",
   "metadata": {},
   "source": [
    "# Episode 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "c7e47ec3-1304-4a5f-9684-3266b1d0b621",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usage: twarc2 counts [OPTIONS] QUERY [OUTFILE]\n",
      "Try 'twarc2 counts --help' for help.\n",
      "\n",
      "Error: Got unexpected extra argument (Barbara))\n",
      "\u001b[33m⚡ \u001b[0m\u001b[31mThere were errors processing your request: no viable alternative at input '[' (at position 2)\u001b[0m\n",
      "2022-05-09T23:13:17.000Z - 2022-05-10T00:00:00.000Z: 0\n",
      "2022-05-10T00:00:00.000Z - 2022-05-11T00:00:00.000Z: 11\n",
      "2022-05-11T00:00:00.000Z - 2022-05-12T00:00:00.000Z: 7\n",
      "2022-05-12T00:00:00.000Z - 2022-05-13T00:00:00.000Z: 11\n",
      "2022-05-13T00:00:00.000Z - 2022-05-14T00:00:00.000Z: 9\n",
      "2022-05-14T00:00:00.000Z - 2022-05-15T00:00:00.000Z: 7\n",
      "2022-05-15T00:00:00.000Z - 2022-05-16T00:00:00.000Z: 5\n",
      "2022-05-16T00:00:00.000Z - 2022-05-16T23:13:17.000Z: 12\n",
      "\u001b[32m\n",
      "Total Tweets: 62\n",
      "\u001b[0m\n",
      "2022-05-09T23:13:19.000Z - 2022-05-10T00:00:00.000Z: 12\n",
      "2022-05-10T00:00:00.000Z - 2022-05-11T00:00:00.000Z: 265\n",
      "2022-05-11T00:00:00.000Z - 2022-05-12T00:00:00.000Z: 370\n",
      "2022-05-12T00:00:00.000Z - 2022-05-13T00:00:00.000Z: 285\n",
      "2022-05-13T00:00:00.000Z - 2022-05-14T00:00:00.000Z: 257\n",
      "2022-05-14T00:00:00.000Z - 2022-05-15T00:00:00.000Z: 244\n",
      "2022-05-15T00:00:00.000Z - 2022-05-16T00:00:00.000Z: 271\n",
      "2022-05-16T00:00:00.000Z - 2022-05-16T23:13:19.000Z: 278\n",
      "\u001b[32m\n",
      "Total Tweets: 1,982\n",
      "\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# phrase searching????\n",
    "!twarc2 counts --granularity \"day\" --text \"(#UCSB OR UCSB OR ucsb OR \"UC Santa Barbara\")\"\n",
    "!twarc2 counts --granularity \"day\" --text \"([uc santa barbara])\"\n",
    "!twarc2 counts --granularity \"day\" --text \"(#ucsb)\"\n",
    "!twarc2 counts --granularity \"day\" --text \"(UCSB)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "021f95fb-293d-459c-9afd-59d624efa865",
   "metadata": {},
   "outputs": [],
   "source": [
    "# search for hashtags when you really want hashtags. \n",
    "# search for a string returns both text and hashtage (an OR)\n",
    "# NOT case sensitive\n",
    "!twarc2 counts --granularity \"day\" --text \"(#UCSB OR UCSB OR ucsb)\"\n",
    "!twarc2 counts --granularity \"day\" --text \"(#ucsb)\"\n",
    "!twarc2 counts --granularity \"day\" --text \"(UCSB)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be3bd639-6118-4983-bb16-1ff7fd3999de",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Endpoints: counts\n",
    "!twarc2 counts --text \"(Poker OR poker)\" --granularity \"day\"\n",
    "!twarc2 counts --text \"(Golf OR golf)\" --granularity \"day\"\n",
    "!twarc2 counts --text \"(Basketball OR basketball)\" --granularity \"day\"\n",
    "!twarc2 counts --text \"(Baseball OR baseball)\" --granularity \"day\"\n",
    "!twarc2 counts --text \"(Football OR football)\" --granularity \"day\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5443c1c7-0da2-4ad9-82fd-1e9b2b377a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "## What's a lot?\n",
    "!twarc2 counts --text \"dog\" --granularity \"day\"\n",
    "!twarc2 counts --text \"cat\" --granularity \"day\"\n",
    "!twarc2 counts --text \"amazon\" --granularity \"day\"\n",
    "!twarc2 counts --text \"right\" --granularity \"day\"\n",
    "!twarc2 counts --text \"good\" --granularity \"day\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b64d9fa-d4d2-49c3-bf09-1e3a9d0ab35b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "c5795ab9-3a2c-4122-bf59-2bf002fa3d1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-05-09T22:52:53.000Z - 2022-05-10T00:00:00.000Z: 0\n",
      "2022-05-10T00:00:00.000Z - 2022-05-11T00:00:00.000Z: 2\n",
      "2022-05-11T00:00:00.000Z - 2022-05-12T00:00:00.000Z: 2\n",
      "2022-05-12T00:00:00.000Z - 2022-05-13T00:00:00.000Z: 0\n",
      "2022-05-13T00:00:00.000Z - 2022-05-14T00:00:00.000Z: 2\n",
      "2022-05-14T00:00:00.000Z - 2022-05-15T00:00:00.000Z: 0\n",
      "2022-05-15T00:00:00.000Z - 2022-05-16T00:00:00.000Z: 0\n",
      "2022-05-16T00:00:00.000Z - 2022-05-16T22:52:53.000Z: 1\n",
      "\u001b[32m\n",
      "Total Tweets: 7\n",
      "\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# recent search with granularity.\n",
    "!twarc2 counts --granularity \"day\" --text \"(#UCSBLibrary OR UCSBLibrary OR ucsblibrary OR #ucsblibrary OR davidsonlibrary OR #davidsonlibrary)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aab1b16f-69c8-4118-af77-dc38a99fc9a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ffc36b3-3fff-455a-b977-af257a34b5dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "abc52493-cf69-4298-8617-515a581ead59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API limit of 3200 reached:  98%|██████████▊| 3226/3278 [00:24<00:00, 130.26it/s]\n",
      "100%|██████████████| Processed 5.30M/5.30M of input file [00:00<00:00, 10.9MB/s]\n",
      "100%|██████████████| Processed 12.9M/12.9M of input file [00:02<00:00, 4.86MB/s]\n",
      "\n",
      "ℹ️\n",
      "Parsed 3226 tweets objects from 3226 lines in the input file.\n",
      "Wrote 3226 rows and output 74 columns in the CSV.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## a SFW timeline\n",
    "!twarc2 timeline ucsblibrary raw_data/library.jsonl\n",
    "!twarc2 flatten raw_data/library.jsonl output_data/library.jsonl\n",
    "!twarc2 csv output_data/library.jsonl output_data/library.csv\n",
    "library_df = pandas.read_csv(\"output_data/library.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc06081-ef7c-4122-b7c0-0901ca4a2dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# confirm the dataframe's existance\n",
    "list(library_df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5af9bd3-debf-4910-a2f1-30a760d599cd",
   "metadata": {},
   "source": [
    "### Converting to csv and dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44e2145d-a912-49ea-8044-544cb11bb38d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!twarc2 csv raw_data/taxday.jsonl output_data/taxday.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb2daed5-e882-4d66-bcdc-f403bb3a6710",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a492aa1b-dd0f-44f0-b0bc-dedec7d38b0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab6d14b4-0c5e-4553-9eb2-7d8d284476af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fishing around for good searches\n",
    "!twarc2 counts --text \"kittens\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee4cc6aa-8a09-4b27-9dab-0b80cf267fcc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "23735a74-0dd1-4483-9705-595042b099bc",
   "metadata": {},
   "source": [
    "## final challenge: Cats of Instagram\n",
    "Let’s make a bigger datafile. Harvest 5000 tweets that use the hashtag “catsofinstagram” and put the dataset through the pipeline to answer the following questions:\n",
    "\n",
    "- Did you get exactly 5000?\n",
    "- How far back in time did you get?\n",
    "- What is the most re-tweeted recent tweet on #catsofinstagram?\n",
    "- Which person has the most number of followers in your dataset?\n",
    "- Is it really a person?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "952eed26-010f-464b-82c9-4699988555b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set --limit of 5000 reached:  35%|▎| Processed 2 days/6 days [00:45<01:23, 5089 \n",
      "    5090  1075715 19340796 output_data/hashtagcats.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    2022-05-20T01:13:20.000Z\n",
       "1    2022-05-20T01:13:08.000Z\n",
       "2    2022-05-20T01:12:52.000Z\n",
       "3    2022-05-20T01:12:49.000Z\n",
       "4    2022-05-20T01:10:45.000Z\n",
       "Name: created_at, dtype: object"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!twarc2 search --limit 5000 \"#catsofinstagram\" raw_data/hashtagcats.jsonl\n",
    "!twarc2 csv raw_data/hashtagcats.jsonl > output_data/hashtagcats.csv\n",
    "hashtagcats_df = pandas.read_csv(\"output_data/hashtagcats.csv\")\n",
    "! wc output_data/hashtagcats.csv\n",
    "hashtagcats_df[\"created_at\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ac420468-385e-4d39-9f8c-d7e5f520c1be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5084    2022-05-17T13:16:20.000Z\n",
       "5085    2022-05-17T13:16:15.000Z\n",
       "5086    2022-05-17T13:13:48.000Z\n",
       "5087    2022-05-17T13:12:47.000Z\n",
       "5088    2022-05-17T13:12:39.000Z\n",
       "Name: created_at, dtype: object"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hashtagcats_df[\"created_at\"].tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f07c72-c097-4db9-8705-32e2b93c6aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "hashtagcats_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c151b25e-f551-445c-93ed-118406e3df40",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(hashtagcats_df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "870d9fb7-03eb-4dcd-9ab8-d4888b008f65",
   "metadata": {},
   "source": [
    "# Episode 5: Ethics & Twitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f046b945-b698-4c9b-b6c4-8047382f16aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# our first full-text analysis\n",
    "# a list of words with TextBlob\n",
    "\n",
    "# first we need to munge the data. remember from:\n",
    "# list(library_df.columns)\n",
    "# the tweet is library_df['text']\n",
    "\n",
    "# TextBlob has its own data format.\n",
    "\n",
    "# break tweets test column into a list, \n",
    "# then .join into one long string \n",
    "library_string = ' '.join(library_df['text'].tolist())\n",
    "# turn the string into a blob\n",
    "library_blob = TextBlob(library_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4522956e-9332-4219-a21b-7e2dfbf3bc02",
   "metadata": {},
   "source": [
    "This produces a mess. we need to filter out the hyperlinks and stop words. And how about a phrase counter?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "1a5a3b36-fffd-477c-91bb-cdf315dbe285",
   "metadata": {},
   "outputs": [],
   "source": [
    "library_freq = library_blob.word_counts\n",
    "library_sorted_freq = sorted(library_freq.items(), \n",
    "                             key = lambda kv: kv[1], \n",
    "                             reverse = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ebad179-03a4-4f7d-aaf8-7fb366dddd77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# can I just do the first bunch?\n",
    "type(library_sorted_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a69badc7-8fa2-4bd1-b556-ff28318f8642",
   "metadata": {},
   "outputs": [],
   "source": [
    "library_sorted_freq[1:25]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfa676be-7ceb-45e8-82e8-7429b8884d7b",
   "metadata": {},
   "source": [
    "We can at least get the english stopwords out. but this all didn't reall produce anything cleaner:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5cd1c12-d78a-44e5-9376-26b4a0589785",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "sw_nltk = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e878e6b7-2c29-45e8-83cd-fb0eefd3b668",
   "metadata": {},
   "outputs": [],
   "source": [
    "library_str_stopped = [word for word in library_string.split() \n",
    "                       if word.lower() not in sw_nltk]\n",
    "stopped_text = \" \".join(library_str_stopped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e27a5b1-0519-407c-ae52-abd0587857a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "library_blob_stopped = TextBlob(stopped_text)\n",
    "library_blob_stopped_freq = library_blob_stopped.word_counts\n",
    "library_blob_stopped_sorted_freq = sorted(library_blob_stopped_freq.items(), \n",
    "                             key = lambda kv: kv[1], \n",
    "                             reverse = True)\n",
    "library_blob_stopped_sorted_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b658645-2144-45c0-9d76-bac57357e9de",
   "metadata": {},
   "outputs": [],
   "source": [
    "library_stopped_blob = [word for word in library_blob.split()\n",
    "                        if word.lower() not in sw_nltk]\n",
    "new_text = \" \".join(library_stopped_blob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c343fbf8-241c-4ec7-8b6e-da4c3db73717",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(library_stopped_blob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e074d32e-4a94-4add-89b3-cf0863340cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Challenge: for the Python wizzes.\n",
    "# do that in a tidy way?\n",
    "# what do pandas pipes look like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3929ae1c-4a37-4cef-9501-7fc2b540f513",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e99fdaca-edb7-41f1-b35c-a82092579ee0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2bc9aad4-1981-4911-ac2e-18bb3b0e92ae",
   "metadata": {},
   "source": [
    "## Challenge: Insta-rrectionists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "fe5551d5-4b64-4731-9285-82bfc5fd9a87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 94%|█████▋| Processed 77401/82309 lines of input file [32:37<00:38, 127.80it/s]^C\n",
      " 94%|██████▌| Processed 77500/82309 lines of input file [32:37<02:01, 39.58it/s]\n",
      "\n",
      "Aborted!\n"
     ]
    }
   ],
   "source": [
    "!twarc2 hydrate raw_data/dehydratedCapitolRiotTweets.txt output_data/riots.jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76119af0-f58e-4bb4-a296-f0718b28a05b",
   "metadata": {},
   "outputs": [],
   "source": [
    "riots_dehydrated_df = pandas.read_csv(\"raw_data/dehydratedCapitolRiotTweets.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae63a6f5-71af-4a07-a940-d96b45ebd1a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "12ca8fc4-ac95-4535-8146-843e2126e915",
   "metadata": {},
   "source": [
    "# Episode 6: Working with our Tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e70e7058-cdc6-4b96-98ef-03d261c3b051",
   "metadata": {},
   "source": [
    "1. retweets\n",
    "1. emojis\n",
    "1. wall\n",
    "1. followers\n",
    "1. retweeted-by"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "76d86256-2a22-4031-9a3d-d76b0ba3f3e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# what does this do?\n",
    "# it shows the tweet ID's of the Retweets in your dataset, and how much\n",
    "!python utils/retweets.py raw_data/taxday.jsonl > output_data/taxday_retweets.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "5281953c-f01a-4d24-ad9e-239aa71470bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jovyan/twarc_run/utils/emojis.py:22: DeprecationWarning: 'emoji.get_emoji_regexp()' is deprecated and will be removed in version 2.0.0. If you want to remove emoji from a string, consider the method emoji.replace_emoji(str, replace='').\n",
      "To hide this warning, pin/downgrade the package to 'emoji~=1.6.3'\n",
      "  EMOJI_RE = emoji.get_emoji_regexp()\n"
     ]
    }
   ],
   "source": [
    "!python utils/emojis.py raw_data/taxday.jsonl > output_data/taxday_emojis.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc855355-2742-47b4-a166-194898ded55b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# we made the utils folder during setup\n",
    "# https://github.com/DocNow/twarc/tree/main/utils\n",
    "\n",
    "!python utils/wall.py raw_data/taxday.jsonl > output_data/taxday_wall.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "187e274c-6481-4f37-8ee5-29806da7be7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████████| Processed 2.41M/2.41M of input file [00:00<00:00, 3.09MB/s]\n",
      "\n",
      "ℹ️\n",
      "Parsed 809 tweets objects from 9 lines in the input file.\n",
      "Wrote 809 rows and output 74 columns in the CSV.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ! twarc2 mentions ucsblibrary raw_data/ucsblibrary_mentions.jsonl\n",
    "! twarc2 csv raw_data/ucsblibrary_mentions.jsonl output_data/ucsblibrary_mentions.csv \n",
    "ucsb_library_mentions_df = pandas.read_csv('output_data/ucsblibrary_mentions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c897bf85-dfc0-4557-af4e-0e662eaa92da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jovyan/twarc_run/utils/emojis.py:22: DeprecationWarning: 'emoji.get_emoji_regexp()' is deprecated and will be removed in version 2.0.0. If you want to remove emoji from a string, consider the method emoji.replace_emoji(str, replace='').\n",
      "To hide this warning, pin/downgrade the package to 'emoji~=1.6.3'\n",
      "  EMOJI_RE = emoji.get_emoji_regexp()\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jovyan/twarc_run/utils/emojis.py\", line 29, in <module>\n",
      "    text = tweet[\"text\"]\n",
      "KeyError: 'text'\n"
     ]
    }
   ],
   "source": [
    "# emojis for each of our datasets so far\n",
    "# !python utils/emojis.py raw_data/hashtagcats.jsonl > output_data/hashtagcats_emojis.csv\n",
    "!python utils/emojis.py raw_data/ucsblibrary_mentions.jsonl > output_data/ucsblibrary_mentions_emojis.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4388d91c-dcfe-4fc3-b215-ff0c2a1c0dda",
   "metadata": {},
   "source": [
    "# Retweets vs. tweets\n",
    "How much original content is there?\n",
    "Do this for both taxday, library, and one of the cats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2442d03-bfc2-4a75-bc8d-3386b30bfe15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with the util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a066d059-1867-449e-8230-72faa359c6e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d6e8c9-2d81-4868-923b-ca5b4c10815e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c965f46-311a-4add-97a0-403a647ee7d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ceb74589-f708-4ab5-9a2b-00c2478d4020",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='Frequency'>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# via pandas and plottting\n",
    "tax_retweets_df = pandas.read_csv(\"output_data/taxday_retweets.csv\", names=[\"tweetid\", \"retweets\"])\n",
    "tax_retweets_df.head()\n",
    "tax_retweets_df[\"retweets\"].plot(kind = \"hist\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "371d1385-a265-4e0b-a36f-064a9b5ac444",
   "metadata": {},
   "outputs": [],
   "source": [
    "retweet_total = sum(tax_retweets_df[\"retweets\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a974343-f4c3-4e3c-99c7-67d975cea76b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tax_retweets_df[\"retweets\"].plot(kind = \"hist\", loglog=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b45c780-7130-4cd3-be66-13d634bb50c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# new beginning\n",
    "# can I get a fresh filter and run emojis?\n",
    "!twarc2 filter "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d6da4f1-7a9a-47ef-a5ce-d4e5a3920752",
   "metadata": {},
   "source": [
    "# Episode 7: Search and Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afb13818-26a5-4d6a-bcf1-f99b3d7c966c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use Twitter advanced search syntax (everthing in quotes!)\n",
    "# to get tailored results\n",
    "!twarc2 search --limit 800 \"(cute OR fluffy OR haircut) (#catsofinstagram) lang:en\" kittens.jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec3cfcd-55cb-4434-b633-b548cb321141",
   "metadata": {},
   "outputs": [],
   "source": [
    "kittens_df = pandas.read_csv(\"output_data/kittens.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c8aa01-430a-4599-a65d-aaac822ff8c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "kittens_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0015b8ec-3e79-46d8-8f76-9aa7c5dc66b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(kittens_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a264ec5-4174-4e62-a3cd-9e16aef94059",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf1a44d-a9ac-447f-85ec-1ebdef13f350",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Episode 8: Analysis Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ccc6de7-126c-4975-8f1e-cacd1140ff34",
   "metadata": {},
   "outputs": [],
   "source": [
    "built-in should come first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c5bbf73-444b-41a2-a72c-deb388217096",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TextBlob needs a string, so this won't work.\n",
    "TextBlob(kittens_df).sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6c3b41d-cfc2-4a41-b710-4145d2fbb0af",
   "metadata": {},
   "source": [
    "### Sentiment Analysis\n",
    "To do this, we need to do a little Python\n",
    "\n",
    "TextBlob is a text processing library that does sentiment analysis. \n",
    "The sentiment property returns a namedtuple of the form Sentiment(polarity, subjectivity). The polarity score is a float within the range [-1.0, 1.0]. The subjectivity is a float within the range [0.0, 1.0] where 0.0 is very objective and 1.0 is very subjective."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd4d69fd-adcc-46a6-9a46-83cb991e52b9",
   "metadata": {},
   "source": [
    "Before we use TextBlob for sentiment analysis, we need to download\n",
    "datasets of words and their associated weights. These are called *corpora*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "423c7d9b-b67d-4b13-8894-75a64654b52d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m textblob.download_corpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6874ca27-b81f-4f4f-911b-68e9fe21384e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# break tweets test column into a list, then .join into one long string \n",
    "kittens_string = ' '.join(kittens_df['text'].tolist())\n",
    "# turn the string into a blob\n",
    "kittens_blob = TextBlob(kittens_string)\n",
    "# get the sentiment\n",
    "kittens_blob.sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "005ba8f5-5054-4fba-8e12-0bade66f4775",
   "metadata": {
    "tags": []
   },
   "source": [
    "The overall sentiment of the language of our kittens tweets is rather positive.\n",
    "And the tweets tend to be subjective."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f7f70c-b9ee-45cf-ad37-7a26cc43d559",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What do you think the sentiment of tax day might be?\n",
    "# get the overall sentiment and see if it matches your prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9856bda0-b290-40a0-ad22-32ece206312b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e03d25-b2af-4102-a418-b6b0532e0aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Episode 9: Data Management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e793dcc-20ec-419e-baab-4b75b308ba0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Episode 10: Don't Map Twitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d4e4d3d-71a6-4fe7-8b30-542ea123b4ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9cd07036-0a35-460c-a76f-523b711918d2",
   "metadata": {},
   "source": [
    "## Create a blob for analysis"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
